Running SLURM prolog script on gold52.cluster.local
===============================================================================
Job started on Tue Oct 26 15:00:42 BST 2021
Job ID          : 597367
Job name        : run_with_different_seeds.sh
WorkDir         : /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud
Command         : ./run_with_different_seeds.sh
Partition       : serial
Num hosts       : 1
Num cores       : 14
Num of tasks    : 14
Hosts allocated : gold52
Job Output Follows ...
===============================================================================
Starting Job
2021-10-26 15:01:09,737	INFO services.py:1247 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
[2m[36m(pid=9755)[0m 2021-10-26 15:01:29,644	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=9767)[0m 2021-10-26 15:01:29,644	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=9797)[0m 2021-10-26 15:01:36,541	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9770)[0m 2021-10-26 15:01:36,541	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9766)[0m 2021-10-26 15:01:36,541	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9785)[0m 2021-10-26 15:01:36,541	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9743)[0m 2021-10-26 15:01:36,542	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9778)[0m 2021-10-26 15:01:36,541	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9777)[0m 2021-10-26 15:01:36,542	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9788)[0m 2021-10-26 15:01:36,542	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9748)[0m 2021-10-26 15:01:36,541	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9796)[0m 2021-10-26 15:01:36,542	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9755)[0m 2021-10-26 15:01:37,204	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9767)[0m 2021-10-26 15:01:37,203	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=9755)[0m 2021-10-26 15:01:37,292	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=9767)[0m 2021-10-26 15:01:37,291	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=9797)[0m 2021-10-26 15:01:37,354	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
[2m[36m(pid=9770)[0m 2021-10-26 15:01:37,354	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
2021-10-26 15:04:36,310	INFO tune.py:545 -- Total run time: 198.35 seconds (197.58 seconds for the tuning loop).
The seed = 124
The random seed = 698

<class 'environments.edge_cloud.simulation.environment.EdgeCloudEnv1'>
start training
== Status ==
Memory usage on this node: 67.4/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/499.3 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 PENDING)
+-------------------------------+----------+-------+--------+--------------------+
| Trial name                    | status   | loc   |     lr |   train_batch_size |
|-------------------------------+----------+-------+--------+--------------------|
| PPO_EdgeCloudEnv1_30c7a_00000 | PENDING  |       | 0.0001 |               3000 |
| PPO_EdgeCloudEnv1_30c7a_00001 | PENDING  |       | 0.001  |               3000 |
+-------------------------------+----------+-------+--------+--------------------+


Result for PPO_EdgeCloudEnv1_30c7a_00001:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-02-19
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: a1692989c71d4f0ea68ac2dd93e4fd35
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.001
          entropy: 1.513871910443177
          entropy_coeff: 0.0
          kl: 0.11704072306168711
          policy_loss: 0.05776758837566852
          total_loss: 17551071.286486488
          vf_explained_var: 0.019300125539302826
          vf_loss: 17551070.964864865
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.70333333333333
    ram_util_percent: 9.186666666666667
  pid: 9767
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.09892738753377729
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.272847536815515
    mean_inference_ms: 1.759023938428392
    mean_raw_obs_processing_ms: 1.6033544404381999
  time_since_restore: 41.863595962524414
  time_this_iter_s: 41.863595962524414
  time_total_s: 41.863595962524414
  timers:
    learn_throughput: 158.958
    learn_time_ms: 19816.499
    sample_throughput: 143.008
    sample_time_ms: 22026.711
    update_time_ms: 4.897
  timestamp: 1635256939
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: 30c7a_00001
  
== Status ==
Memory usage on this node: 68.7/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.3 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc               |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_30c7a_00000 | RUNNING  |                   | 0.0001 |               3000 |        |                  |      |          |                      |                      |                    |
| PPO_EdgeCloudEnv1_30c7a_00001 | RUNNING  | 10.13.39.107:9767 | 0.001  |               3000 |      1 |          41.8636 | 3150 |    24082 |              27658.6 |              19975.5 |                 30 |
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_30c7a_00000:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-02-20
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 7ff2078e86e6473cbdb3941b99ef3fe5
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5996981921496691
          entropy_coeff: 0.0
          kl: 0.008815318613239533
          policy_loss: 0.0014780368991531767
          total_loss: 17552714.26891892
          vf_explained_var: 0.0035156048834323883
          vf_loss: 17552713.961711712
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.614285714285714
    ram_util_percent: 9.182539682539684
  pid: 9755
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10157613860068343
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.69609235470345
    mean_inference_ms: 1.77520987726807
    mean_raw_obs_processing_ms: 1.6479467249899011
  time_since_restore: 43.66726016998291
  time_this_iter_s: 43.66726016998291
  time_total_s: 43.66726016998291
  timers:
    learn_throughput: 148.382
    learn_time_ms: 21228.927
    sample_throughput: 140.536
    sample_time_ms: 22414.226
    update_time_ms: 3.919
  timestamp: 1635256940
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: 30c7a_00000
  
Result for PPO_EdgeCloudEnv1_30c7a_00001:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 28.60952380952381
    Allocated Tasks Number_min: 25
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.504761904761905
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7886.312692320824
    Social Welfare (Random Allocation)_mean: 5454.690507335335
    Social Welfare (Random Allocation)_min: 3993.6764038328247
    Social Welfare_max: 8857.690324940027
    Social Welfare_mean: 7595.790692926532
    Social Welfare_min: 6212.450802427609
  date: 2021-10-26_15-03-00
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 26573.070974820075
  episode_reward_mean: 22787.372078779597
  episode_reward_min: 18637.3524072828
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: a1692989c71d4f0ea68ac2dd93e4fd35
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.001
          entropy: 1.2516942950142074
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15826879244482328
          total_loss: .inf
          vf_explained_var: 0.08230109512805939
          vf_loss: 14567135.024324324
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.42999999999999
    ram_util_percent: 9.171666666666669
  pid: 9767
  policy_reward_max:
    default: 8857.690324940027
  policy_reward_mean:
    default: 7595.790692926533
  policy_reward_min:
    default: 6212.450802427609
  sampler_perf:
    mean_action_processing_ms: 0.09641930945424404
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.794137351197154
    mean_inference_ms: 1.7122369640692183
    mean_raw_obs_processing_ms: 1.6074935752753694
  time_since_restore: 83.54269647598267
  time_this_iter_s: 41.67910051345825
  time_total_s: 83.54269647598267
  timers:
    learn_throughput: 156.129
    learn_time_ms: 20175.609
    sample_throughput: 146.006
    sample_time_ms: 21574.518
    update_time_ms: 4.533
  timestamp: 1635256980
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: 30c7a_00001
  
== Status ==
Memory usage on this node: 69.0/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.3 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_3_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_2_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_1_2ebcba9556f7fc5654bb7534383f3bff, 0.0/6.0 CPU_group_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_0_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_4_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_3_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_0_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_5_2ebcba9556f7fc5654bb7534383f3bff, 0.0/6.0 CPU_group_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_1_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_5_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_2_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_4_2510a6a45c6cb1519e4e3de78ccff779)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc               |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_30c7a_00000 | RUNNING  | 10.13.39.107:9755 | 0.0001 |               3000 |      1 |          43.6673 | 3150 |  24082   |              27658.6 |              19975.5 |                 30 |
| PPO_EdgeCloudEnv1_30c7a_00001 | RUNNING  | 10.13.39.107:9767 | 0.001  |               3000 |      2 |          83.5427 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_30c7a_00000:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.409523809523808
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 2
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7899.162126828118
    Social Welfare (Random Allocation)_mean: 5457.097407951896
    Social Welfare (Random Allocation)_min: 3888.1292006071553
    Social Welfare_max: 9206.785565279099
    Social Welfare_mean: 7999.137798974094
    Social Welfare_min: 6714.454867620475
  date: 2021-10-26_15-03-06
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27620.3566958373
  episode_reward_mean: 23997.413396922282
  episode_reward_min: 20143.364602861435
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 7ff2078e86e6473cbdb3941b99ef3fe5
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.584746137556729
          entropy_coeff: 0.0
          kl: 0.018195911197172728
          policy_loss: 0.004404350303557621
          total_loss: 16873026.68738739
          vf_explained_var: 0.014319381676614285
          vf_loss: 16873026.40135135
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.496875
    ram_util_percent: 9.1671875
  pid: 9755
  policy_reward_max:
    default: 9206.785565279099
  policy_reward_mean:
    default: 7999.137798974094
  policy_reward_min:
    default: 6714.454867620475
  sampler_perf:
    mean_action_processing_ms: 0.09962538704807845
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.358575621263835
    mean_inference_ms: 1.7339086646035398
    mean_raw_obs_processing_ms: 1.6736153852930151
  time_since_restore: 88.84277892112732
  time_this_iter_s: 45.17551875114441
  time_total_s: 88.84277892112732
  timers:
    learn_throughput: 145.998
    learn_time_ms: 21575.679
    sample_throughput: 138.034
    sample_time_ms: 22820.426
    update_time_ms: 4.729
  timestamp: 1635256986
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: 30c7a_00000
  
== Status ==
Memory usage on this node: 69.0/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.3 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_2_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_2_2ebcba9556f7fc5654bb7534383f3bff, 0.0/6.0 CPU_group_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_3_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_3_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_1_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_4_2510a6a45c6cb1519e4e3de78ccff779, 0.0/6.0 CPU_group_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_4_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_0_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_5_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_5_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_1_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_0_2ebcba9556f7fc5654bb7534383f3bff)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc               |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_30c7a_00000 | RUNNING  | 10.13.39.107:9755 | 0.0001 |               3000 |      2 |          88.8428 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_30c7a_00001 | RUNNING  | 10.13.39.107:9767 | 0.001  |               3000 |      2 |          83.5427 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_30c7a_00001:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.533333333333335
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 6.20952380952381
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7561.037728969207
    Social Welfare (Random Allocation)_mean: 5639.056399037374
    Social Welfare (Random Allocation)_min: 3444.0735201120983
    Social Welfare_max: 9393.3159210423
    Social Welfare_mean: 8191.429139103084
    Social Welfare_min: 6668.9270033924095
  date: 2021-10-26_15-03-43
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28179.947763126926
  episode_reward_mean: 24574.287417309253
  episode_reward_min: 20006.78101017722
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: a1692989c71d4f0ea68ac2dd93e4fd35
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.4500000000000001
          cur_lr: 0.001
          entropy: 0.9873753228405804
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15913675058977092
          total_loss: .inf
          vf_explained_var: 0.16473977267742157
          vf_loss: 16097216.598648649
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.44000000000001
    ram_util_percent: 9.166666666666664
  pid: 9767
  policy_reward_max:
    default: 9393.3159210423
  policy_reward_mean:
    default: 8191.429139103086
  policy_reward_min:
    default: 6668.9270033924095
  sampler_perf:
    mean_action_processing_ms: 0.09515508654759337
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.488660342349124
    mean_inference_ms: 1.688961778476338
    mean_raw_obs_processing_ms: 1.597309995113637
  time_since_restore: 125.70970964431763
  time_this_iter_s: 42.16701316833496
  time_total_s: 125.70970964431763
  timers:
    learn_throughput: 153.715
    learn_time_ms: 20492.42
    sample_throughput: 147.262
    sample_time_ms: 21390.488
    update_time_ms: 4.001
  timestamp: 1635257023
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: 30c7a_00001
  
== Status ==
Memory usage on this node: 70.1/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.3 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_2_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_2_2ebcba9556f7fc5654bb7534383f3bff, 0.0/6.0 CPU_group_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_3_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_3_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_1_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_4_2510a6a45c6cb1519e4e3de78ccff779, 0.0/6.0 CPU_group_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_4_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_0_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_5_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_5_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_1_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_0_2ebcba9556f7fc5654bb7534383f3bff)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc               |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_30c7a_00000 | RUNNING  | 10.13.39.107:9755 | 0.0001 |               3000 |      2 |          88.8428 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_30c7a_00001 | RUNNING  | 10.13.39.107:9767 | 0.001  |               3000 |      3 |         125.71   | 9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_30c7a_00000:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.419047619047618
    Allocated Tasks Number_min: 27
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.828571428571428
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7500.308337068168
    Social Welfare (Random Allocation)_mean: 5593.45734795943
    Social Welfare (Random Allocation)_min: 3758.2663214270156
    Social Welfare_max: 9294.820375261532
    Social Welfare_mean: 8038.417341800684
    Social Welfare_min: 6445.078494603251
  date: 2021-10-26_15-03-51
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27884.4611257846
  episode_reward_mean: 24115.252025402053
  episode_reward_min: 19335.23548380974
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 7ff2078e86e6473cbdb3941b99ef3fe5
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5625350365767607
          entropy_coeff: 0.0
          kl: 0.023187605126125617
          policy_loss: 0.008069554482049704
          total_loss: 16464452.908108108
          vf_explained_var: 0.03559638187289238
          vf_loss: 16464452.673423423
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.60461538461538
    ram_util_percent: 9.186153846153845
  pid: 9755
  policy_reward_max:
    default: 9294.820375261532
  policy_reward_mean:
    default: 8038.417341800683
  policy_reward_min:
    default: 6445.078494603251
  sampler_perf:
    mean_action_processing_ms: 0.09847814478236241
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.155531632591337
    mean_inference_ms: 1.7148711579240612
    mean_raw_obs_processing_ms: 1.665116793765144
  time_since_restore: 134.45158338546753
  time_this_iter_s: 45.60880446434021
  time_total_s: 134.45158338546753
  timers:
    learn_throughput: 143.51
    learn_time_ms: 21949.656
    sample_throughput: 137.895
    sample_time_ms: 22843.55
    update_time_ms: 4.334
  timestamp: 1635257031
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: 30c7a_00000
  
== Status ==
Memory usage on this node: 70.4/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.3 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_4_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_2_2510a6a45c6cb1519e4e3de78ccff779, 0.0/6.0 CPU_group_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_1_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_5_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_0_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_1_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_4_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_2_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_3_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_3_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_5_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_0_2ebcba9556f7fc5654bb7534383f3bff)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc               |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_30c7a_00000 | RUNNING  | 10.13.39.107:9755 | 0.0001 |               3000 |      3 |          134.452 | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_30c7a_00001 | RUNNING  | 10.13.39.107:9767 | 0.001  |               3000 |      3 |          125.71  | 9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_30c7a_00001:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.79047619047619
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 15
    Bad Allocations Number_mean: 7.104761904761904
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7226.507746909067
    Social Welfare (Random Allocation)_mean: 5645.498463884971
    Social Welfare (Random Allocation)_min: 4284.401252245399
    Social Welfare_max: 9260.343498766093
    Social Welfare_mean: 8414.514033610567
    Social Welfare_min: 6964.4019115518095
  date: 2021-10-26_15-04-25
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27781.03049629827
  episode_reward_mean: 25243.5421008317
  episode_reward_min: 20893.205734655414
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: a1692989c71d4f0ea68ac2dd93e4fd35
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.6749999999999998
          cur_lr: 0.001
          entropy: 0.9576918035449724
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.16871869819425467
          total_loss: .inf
          vf_explained_var: 0.1990945041179657
          vf_loss: 16136426.923873873
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.95166666666667
    ram_util_percent: 9.213333333333336
  pid: 9767
  policy_reward_max:
    default: 9260.343498766093
  policy_reward_mean:
    default: 8414.514033610567
  policy_reward_min:
    default: 6964.4019115518095
  sampler_perf:
    mean_action_processing_ms: 0.09440571861766438
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.166406679134525
    mean_inference_ms: 1.6732844981065298
    mean_raw_obs_processing_ms: 1.5997727964190163
  time_since_restore: 167.63691663742065
  time_this_iter_s: 41.92720699310303
  time_total_s: 167.63691663742065
  timers:
    learn_throughput: 151.575
    learn_time_ms: 20781.84
    sample_throughput: 149.241
    sample_time_ms: 21106.772
    update_time_ms: 3.74
  timestamp: 1635257065
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: 30c7a_00001
  
== Status ==
Memory usage on this node: 69.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.3 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_4_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_2_2510a6a45c6cb1519e4e3de78ccff779, 0.0/6.0 CPU_group_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_1_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_5_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_0_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_1_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_4_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_2_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_3_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_3_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_5_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_0_2ebcba9556f7fc5654bb7534383f3bff)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc               |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_30c7a_00000 | RUNNING  | 10.13.39.107:9755 | 0.0001 |               3000 |      3 |          134.452 |  9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_30c7a_00001 | RUNNING  | 10.13.39.107:9767 | 0.001  |               3000 |      4 |          167.637 | 12600 |  25243.5 |              27781   |              20893.2 |                 30 |
+-------------------------------+----------+-------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_30c7a_00000:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.64761904761905
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7595.848139463799
    Social Welfare (Random Allocation)_mean: 5713.912731429197
    Social Welfare (Random Allocation)_min: 4210.0886792356905
    Social Welfare_max: 9356.013150952798
    Social Welfare_mean: 8157.091040975737
    Social Welfare_min: 6596.6455070559105
  date: 2021-10-26_15-04-35
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28068.039452858404
  episode_reward_mean: 24471.273122927214
  episode_reward_min: 19789.936521167747
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 7ff2078e86e6473cbdb3941b99ef3fe5
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.00010000000000000003
          entropy: 1.545704576507345
          entropy_coeff: 0.0
          kl: 0.0212652327241367
          policy_loss: 0.007853564555307868
          total_loss: 16564141.26036036
          vf_explained_var: 0.04438931494951248
          vf_loss: 16564141.00045045
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 46.14761904761905
    ram_util_percent: 9.173015873015874
  pid: 9755
  policy_reward_max:
    default: 9356.013150952798
  policy_reward_mean:
    default: 8157.091040975736
  policy_reward_min:
    default: 6596.6455070559105
  sampler_perf:
    mean_action_processing_ms: 0.09783853003544639
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.93515607432116
    mean_inference_ms: 1.7023789036231394
    mean_raw_obs_processing_ms: 1.6695975500740072
  time_since_restore: 178.22226214408875
  time_this_iter_s: 43.770678758621216
  time_total_s: 178.22226214408875
  timers:
    learn_throughput: 143.202
    learn_time_ms: 21996.859
    sample_throughput: 139.773
    sample_time_ms: 22536.52
    update_time_ms: 3.874
  timestamp: 1635257075
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: 30c7a_00000
  
== Status ==
Memory usage on this node: 68.3/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 6.0/64 CPUs, 0/0 GPUs, 0.0/499.3 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_3_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_0_2510a6a45c6cb1519e4e3de78ccff779, 0.0/6.0 CPU_group_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_1_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_5_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_5_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_4_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_4_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_2_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_1_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_3_2510a6a45c6cb1519e4e3de78ccff779, 0.0/6.0 CPU_group_2510a6a45c6cb1519e4e3de78ccff779, 0.0/1.0 CPU_group_0_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_2_2510a6a45c6cb1519e4e3de78ccff779)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)
+-------------------------------+------------+-------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc               |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+-------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_30c7a_00000 | RUNNING    | 10.13.39.107:9755 | 0.0001 |               3000 |      4 |          178.222 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_30c7a_00001 | TERMINATED |                   | 0.001  |               3000 |      4 |          167.637 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
+-------------------------------+------------+-------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 68.3/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/499.3 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_5_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_4_2ebcba9556f7fc5654bb7534383f3bff, 0.0/6.0 CPU_group_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_0_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_2_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_3_2ebcba9556f7fc5654bb7534383f3bff, 0.0/1.0 CPU_group_1_2ebcba9556f7fc5654bb7534383f3bff)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 TERMINATED)
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc   |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_30c7a_00000 | TERMINATED |       | 0.0001 |               3000 |      4 |          178.222 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_30c7a_00001 | TERMINATED |       | 0.001  |               3000 |      4 |          167.637 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x2afc6e433320>
2021-10-26 15:05:01,963	INFO services.py:1247 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
[2m[36m(pid=12298)[0m 2021-10-26 15:05:19,041	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=12300)[0m 2021-10-26 15:05:19,041	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=12245)[0m 2021-10-26 15:05:25,107	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12282)[0m 2021-10-26 15:05:25,107	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12258)[0m 2021-10-26 15:05:25,107	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12295)[0m 2021-10-26 15:05:25,107	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12294)[0m 2021-10-26 15:05:25,108	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12297)[0m 2021-10-26 15:05:25,107	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12287)[0m 2021-10-26 15:05:25,107	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12240)[0m 2021-10-26 15:05:25,107	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12299)[0m 2021-10-26 15:05:25,107	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12251)[0m 2021-10-26 15:05:25,107	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12298)[0m 2021-10-26 15:05:25,415	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12300)[0m 2021-10-26 15:05:25,415	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=12298)[0m 2021-10-26 15:05:25,487	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=12300)[0m 2021-10-26 15:05:25,487	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=12245)[0m 2021-10-26 15:05:25,547	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
[2m[36m(pid=12282)[0m 2021-10-26 15:05:25,547	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
2021-10-26 15:08:18,843	INFO tune.py:545 -- Total run time: 188.38 seconds (187.26 seconds for the tuning loop).
The seed = 124
The random seed = 833

<class 'environments.edge_cloud.simulation.environment.EdgeCloudEnv1'>
start training
== Status ==
Memory usage on this node: 67.7/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/499.05 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 PENDING)
+-------------------------------+----------+-------+--------+--------------------+
| Trial name                    | status   | loc   |     lr |   train_batch_size |
|-------------------------------+----------+-------+--------+--------------------|
| PPO_EdgeCloudEnv1_bb5d2_00000 | PENDING  |       | 0.0001 |               3000 |
| PPO_EdgeCloudEnv1_bb5d2_00001 | PENDING  |       | 0.001  |               3000 |
+-------------------------------+----------+-------+--------+--------------------+


Result for PPO_EdgeCloudEnv1_bb5d2_00000:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-06-06
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 7b99b6d55f264f04883227effcd16c3a
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5996981921496691
          entropy_coeff: 0.0
          kl: 0.008815318613239533
          policy_loss: 0.0014780368991531767
          total_loss: 17552714.26891892
          vf_explained_var: 0.0035156048834323883
          vf_loss: 17552713.961711712
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.786440677966105
    ram_util_percent: 9.189830508474575
  pid: 12298
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10052634116775828
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.280786837715347
    mean_inference_ms: 1.771374549805267
    mean_raw_obs_processing_ms: 1.6553113275397977
  time_since_restore: 40.946569204330444
  time_this_iter_s: 40.946569204330444
  time_total_s: 40.946569204330444
  timers:
    learn_throughput: 167.508
    learn_time_ms: 18805.083
    sample_throughput: 142.417
    sample_time_ms: 22118.17
    update_time_ms: 4.452
  timestamp: 1635257166
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: bb5d2_00000
  
== Status ==
Memory usage on this node: 69.1/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.05 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_bb5d2_00000 | RUNNING  | 10.13.39.107:12298 | 0.0001 |               3000 |      1 |          40.9466 | 3150 |    24082 |              27658.6 |              19975.5 |                 30 |
| PPO_EdgeCloudEnv1_bb5d2_00001 | RUNNING  |                    | 0.001  |               3000 |        |                  |      |          |                      |                      |                    |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_bb5d2_00001:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-06-07
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 2c79824d08b24d4fa22c03cc0f4d2596
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.001
          entropy: 1.513871910443177
          entropy_coeff: 0.0
          kl: 0.11704072306168711
          policy_loss: 0.05776758837566852
          total_loss: 17551071.286486488
          vf_explained_var: 0.019300125539302826
          vf_loss: 17551070.964864865
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.68524590163934
    ram_util_percent: 9.186885245901639
  pid: 12300
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10099939990156993
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.87965895143439
    mean_inference_ms: 1.7627463665703775
    mean_raw_obs_processing_ms: 1.6311773974241817
  time_since_restore: 42.37438941001892
  time_this_iter_s: 42.37438941001892
  time_total_s: 42.37438941001892
  timers:
    learn_throughput: 154.4
    learn_time_ms: 20401.559
    sample_throughput: 143.529
    sample_time_ms: 21946.774
    update_time_ms: 3.937
  timestamp: 1635257167
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: bb5d2_00001
  
Result for PPO_EdgeCloudEnv1_bb5d2_00000:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.409523809523808
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 2
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7899.162126828118
    Social Welfare (Random Allocation)_mean: 5457.097407951896
    Social Welfare (Random Allocation)_min: 3888.1292006071553
    Social Welfare_max: 9206.785565279099
    Social Welfare_mean: 7999.137798974094
    Social Welfare_min: 6714.454867620475
  date: 2021-10-26_15-06-47
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27620.3566958373
  episode_reward_mean: 23997.413396922282
  episode_reward_min: 20143.364602861435
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 7b99b6d55f264f04883227effcd16c3a
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.584746137556729
          entropy_coeff: 0.0
          kl: 0.018195911197172728
          policy_loss: 0.004404350303557621
          total_loss: 16873026.68738739
          vf_explained_var: 0.014319381676614285
          vf_loss: 16873026.40135135
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.505172413793105
    ram_util_percent: 8.85
  pid: 12298
  policy_reward_max:
    default: 9206.785565279099
  policy_reward_mean:
    default: 7999.137798974094
  policy_reward_min:
    default: 6714.454867620475
  sampler_perf:
    mean_action_processing_ms: 0.09732284213133409
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.961830807715337
    mean_inference_ms: 1.715457032919875
    mean_raw_obs_processing_ms: 1.62959113941601
  time_since_restore: 81.87047100067139
  time_this_iter_s: 40.92390179634094
  time_total_s: 81.87047100067139
  timers:
    learn_throughput: 165.122
    learn_time_ms: 19076.831
    sample_throughput: 144.254
    sample_time_ms: 21836.482
    update_time_ms: 3.844
  timestamp: 1635257207
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: bb5d2_00000
  
== Status ==
Memory usage on this node: 66.0/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.05 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_3_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_3_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_2_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_0_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_0_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_2_91a409db96567215ca74c356e6d664c4, 0.0/6.0 CPU_group_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_1_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_4_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_4_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_1_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_5_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_5_91a409db96567215ca74c356e6d664c4)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_bb5d2_00000 | RUNNING  | 10.13.39.107:12298 | 0.0001 |               3000 |      2 |          81.8705 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_bb5d2_00001 | RUNNING  | 10.13.39.107:12300 | 0.001  |               3000 |      1 |          42.3744 | 3150 |  24082   |              27658.6 |              19975.5 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_bb5d2_00001:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 28.60952380952381
    Allocated Tasks Number_min: 25
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.504761904761905
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7886.312692320824
    Social Welfare (Random Allocation)_mean: 5454.690507335335
    Social Welfare (Random Allocation)_min: 3993.6764038328247
    Social Welfare_max: 8857.690324940027
    Social Welfare_mean: 7595.790692926532
    Social Welfare_min: 6212.450802427609
  date: 2021-10-26_15-06-51
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 26573.070974820075
  episode_reward_mean: 22787.372078779597
  episode_reward_min: 18637.3524072828
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 2c79824d08b24d4fa22c03cc0f4d2596
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.001
          entropy: 1.2516942950142074
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15826879244482328
          total_loss: .inf
          vf_explained_var: 0.08230109512805939
          vf_loss: 14567135.024324324
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.645161290322584
    ram_util_percent: 8.827419354838712
  pid: 12300
  policy_reward_max:
    default: 8857.690324940027
  policy_reward_mean:
    default: 7595.790692926533
  policy_reward_min:
    default: 6212.450802427609
  sampler_perf:
    mean_action_processing_ms: 0.09944149655637809
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.606683135127184
    mean_inference_ms: 1.696798973476764
    mean_raw_obs_processing_ms: 1.6156167855440484
  time_since_restore: 85.59946823120117
  time_this_iter_s: 43.22507882118225
  time_total_s: 85.59946823120117
  timers:
    learn_throughput: 150.719
    learn_time_ms: 20899.779
    sample_throughput: 143.993
    sample_time_ms: 21876.004
    update_time_ms: 3.692
  timestamp: 1635257211
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: bb5d2_00001
  
Result for PPO_EdgeCloudEnv1_bb5d2_00000:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.419047619047618
    Allocated Tasks Number_min: 27
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.828571428571428
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7500.308337068168
    Social Welfare (Random Allocation)_mean: 5593.45734795943
    Social Welfare (Random Allocation)_min: 3758.2663214270156
    Social Welfare_max: 9294.820375261532
    Social Welfare_mean: 8038.417341800684
    Social Welfare_min: 6445.078494603251
  date: 2021-10-26_15-07-28
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27884.4611257846
  episode_reward_mean: 24115.252025402053
  episode_reward_min: 19335.23548380974
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 7b99b6d55f264f04883227effcd16c3a
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5625350365767607
          entropy_coeff: 0.0
          kl: 0.023187605126125617
          policy_loss: 0.008069554482049704
          total_loss: 16464452.908108108
          vf_explained_var: 0.03559638187289238
          vf_loss: 16464452.673423423
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 48.108474576271185
    ram_util_percent: 8.586440677966102
  pid: 12298
  policy_reward_max:
    default: 9294.820375261532
  policy_reward_mean:
    default: 8038.417341800683
  policy_reward_min:
    default: 6445.078494603251
  sampler_perf:
    mean_action_processing_ms: 0.09643657065017835
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.772431203639417
    mean_inference_ms: 1.6963589575982865
    mean_raw_obs_processing_ms: 1.647750339074339
  time_since_restore: 123.2307276725769
  time_this_iter_s: 41.36025667190552
  time_total_s: 123.2307276725769
  timers:
    learn_throughput: 163.097
    learn_time_ms: 19313.714
    sample_throughput: 144.883
    sample_time_ms: 21741.692
    update_time_ms: 3.634
  timestamp: 1635257248
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: bb5d2_00000
  
== Status ==
Memory usage on this node: 64.4/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.05 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_3_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_0_f2493bef3ccbb85c045752ca1ac412d0, 0.0/6.0 CPU_group_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_4_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_5_91a409db96567215ca74c356e6d664c4, 0.0/6.0 CPU_group_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_1_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_4_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_0_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_3_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_5_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_1_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_2_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_2_91a409db96567215ca74c356e6d664c4)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_bb5d2_00000 | RUNNING  | 10.13.39.107:12298 | 0.0001 |               3000 |      3 |         123.231  | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_bb5d2_00001 | RUNNING  | 10.13.39.107:12300 | 0.001  |               3000 |      2 |          85.5995 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_bb5d2_00001:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.533333333333335
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 6.20952380952381
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7561.037728969207
    Social Welfare (Random Allocation)_mean: 5639.056399037374
    Social Welfare (Random Allocation)_min: 3444.0735201120983
    Social Welfare_max: 9393.3159210423
    Social Welfare_mean: 8191.429139103084
    Social Welfare_min: 6668.9270033924095
  date: 2021-10-26_15-07-34
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28179.947763126926
  episode_reward_mean: 24574.287417309253
  episode_reward_min: 20006.78101017722
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 2c79824d08b24d4fa22c03cc0f4d2596
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.4500000000000001
          cur_lr: 0.001
          entropy: 0.9873753228405804
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15913675058977092
          total_loss: .inf
          vf_explained_var: 0.16473977267742157
          vf_loss: 16097216.598648649
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.92258064516129
    ram_util_percent: 8.562903225806451
  pid: 12300
  policy_reward_max:
    default: 9393.3159210423
  policy_reward_mean:
    default: 8191.429139103086
  policy_reward_min:
    default: 6668.9270033924095
  sampler_perf:
    mean_action_processing_ms: 0.09954526650092388
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.648328773058754
    mean_inference_ms: 1.6834894227704191
    mean_raw_obs_processing_ms: 1.604999328403483
  time_since_restore: 129.0908260345459
  time_this_iter_s: 43.49135780334473
  time_total_s: 129.0908260345459
  timers:
    learn_throughput: 148.924
    learn_time_ms: 21151.731
    sample_throughput: 144.13
    sample_time_ms: 21855.301
    update_time_ms: 3.514
  timestamp: 1635257254
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: bb5d2_00001
  
== Status ==
Memory usage on this node: 64.1/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.05 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_1_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_3_f2493bef3ccbb85c045752ca1ac412d0, 0.0/6.0 CPU_group_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_2_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_4_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_2_f2493bef3ccbb85c045752ca1ac412d0, 0.0/6.0 CPU_group_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_4_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_0_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_1_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_5_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_0_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_3_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_5_91a409db96567215ca74c356e6d664c4)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_bb5d2_00000 | RUNNING  | 10.13.39.107:12298 | 0.0001 |               3000 |      3 |          123.231 | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_bb5d2_00001 | RUNNING  | 10.13.39.107:12300 | 0.001  |               3000 |      3 |          129.091 | 9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_bb5d2_00000:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.64761904761905
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7595.848139463799
    Social Welfare (Random Allocation)_mean: 5713.912731429197
    Social Welfare (Random Allocation)_min: 4210.0886792356905
    Social Welfare_max: 9356.013150952798
    Social Welfare_mean: 8157.091040975737
    Social Welfare_min: 6596.6455070559105
  date: 2021-10-26_15-08-09
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28068.039452858404
  episode_reward_mean: 24471.273122927214
  episode_reward_min: 19789.936521167747
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 7b99b6d55f264f04883227effcd16c3a
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.00010000000000000003
          entropy: 1.545704576507345
          entropy_coeff: 0.0
          kl: 0.0212652327241367
          policy_loss: 0.007853564555307868
          total_loss: 16564141.26036036
          vf_explained_var: 0.04438931494951248
          vf_loss: 16564141.00045045
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.48620689655172
    ram_util_percent: 8.677586206896551
  pid: 12298
  policy_reward_max:
    default: 9356.013150952798
  policy_reward_mean:
    default: 8157.091040975736
  policy_reward_min:
    default: 6596.6455070559105
  sampler_perf:
    mean_action_processing_ms: 0.09577237439032632
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.61868753701815
    mean_inference_ms: 1.6833274149790685
    mean_raw_obs_processing_ms: 1.6456783692640993
  time_since_restore: 163.83382153511047
  time_this_iter_s: 40.60309386253357
  time_total_s: 163.83382153511047
  timers:
    learn_throughput: 162.536
    learn_time_ms: 19380.356
    sample_throughput: 146.125
    sample_time_ms: 21556.881
    update_time_ms: 3.271
  timestamp: 1635257289
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: bb5d2_00000
  
== Status ==
Memory usage on this node: 67.0/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.05 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_1_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_3_f2493bef3ccbb85c045752ca1ac412d0, 0.0/6.0 CPU_group_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_2_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_4_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_2_f2493bef3ccbb85c045752ca1ac412d0, 0.0/6.0 CPU_group_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_4_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_0_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_1_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_5_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_0_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_3_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_5_91a409db96567215ca74c356e6d664c4)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_bb5d2_00000 | RUNNING  | 10.13.39.107:12298 | 0.0001 |               3000 |      4 |          163.834 | 12600 |  24471.3 |              28068   |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_bb5d2_00001 | RUNNING  | 10.13.39.107:12300 | 0.001  |               3000 |      3 |          129.091 |  9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_bb5d2_00001:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.79047619047619
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 15
    Bad Allocations Number_mean: 7.104761904761904
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7226.507746909067
    Social Welfare (Random Allocation)_mean: 5645.498463884971
    Social Welfare (Random Allocation)_min: 4284.401252245399
    Social Welfare_max: 9260.343498766093
    Social Welfare_mean: 8414.514033610567
    Social Welfare_min: 6964.4019115518095
  date: 2021-10-26_15-08-17
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27781.03049629827
  episode_reward_mean: 25243.5421008317
  episode_reward_min: 20893.205734655414
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 2c79824d08b24d4fa22c03cc0f4d2596
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.6749999999999998
          cur_lr: 0.001
          entropy: 0.9576918035449724
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.16871869819425467
          total_loss: .inf
          vf_explained_var: 0.1990945041179657
          vf_loss: 16136426.923873873
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 46.33934426229508
    ram_util_percent: 8.716393442622953
  pid: 12300
  policy_reward_max:
    default: 9260.343498766093
  policy_reward_mean:
    default: 8414.514033610567
  policy_reward_min:
    default: 6964.4019115518095
  sampler_perf:
    mean_action_processing_ms: 0.09891276603556493
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.58924826153305
    mean_inference_ms: 1.6737231088507416
    mean_raw_obs_processing_ms: 1.6065235886957758
  time_since_restore: 172.14720034599304
  time_this_iter_s: 43.056374311447144
  time_total_s: 172.14720034599304
  timers:
    learn_throughput: 148.421
    learn_time_ms: 21223.374
    sample_throughput: 144.554
    sample_time_ms: 21791.182
    update_time_ms: 3.368
  timestamp: 1635257297
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: bb5d2_00001
  
== Status ==
Memory usage on this node: 66.3/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 6.0/64 CPUs, 0/0 GPUs, 0.0/499.05 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_5_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_1_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_3_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_4_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_0_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_2_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_4_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_2_f2493bef3ccbb85c045752ca1ac412d0, 0.0/6.0 CPU_group_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_3_f2493bef3ccbb85c045752ca1ac412d0, 0.0/6.0 CPU_group_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_0_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_1_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_5_91a409db96567215ca74c356e6d664c4)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_bb5d2_00001 | RUNNING    | 10.13.39.107:12300 | 0.001  |               3000 |      4 |          172.147 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
| PPO_EdgeCloudEnv1_bb5d2_00000 | TERMINATED |                    | 0.0001 |               3000 |      4 |          163.834 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 66.3/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/499.05 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_5_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_1_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_3_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_4_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_0_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_2_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_4_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_2_f2493bef3ccbb85c045752ca1ac412d0, 0.0/6.0 CPU_group_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_3_f2493bef3ccbb85c045752ca1ac412d0, 0.0/6.0 CPU_group_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_0_91a409db96567215ca74c356e6d664c4, 0.0/1.0 CPU_group_1_f2493bef3ccbb85c045752ca1ac412d0, 0.0/1.0 CPU_group_5_91a409db96567215ca74c356e6d664c4)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 TERMINATED)
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc   |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_bb5d2_00000 | TERMINATED |       | 0.0001 |               3000 |      4 |          163.834 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_bb5d2_00001 | TERMINATED |       | 0.001  |               3000 |      4 |          172.147 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x2b2db9b563c8>
2021-10-26 15:08:37,208	INFO services.py:1247 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
[2m[36m(pid=14856)[0m 2021-10-26 15:08:52,779	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=14815)[0m 2021-10-26 15:08:52,779	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=14842)[0m 2021-10-26 15:08:58,537	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14850)[0m 2021-10-26 15:08:58,537	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14844)[0m 2021-10-26 15:08:58,538	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14838)[0m 2021-10-26 15:08:58,537	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14853)[0m 2021-10-26 15:08:58,537	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14836)[0m 2021-10-26 15:08:58,537	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14840)[0m 2021-10-26 15:08:58,537	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14808)[0m 2021-10-26 15:08:58,537	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14798)[0m 2021-10-26 15:08:58,537	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14849)[0m 2021-10-26 15:08:58,538	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14856)[0m 2021-10-26 15:08:58,874	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14815)[0m 2021-10-26 15:08:58,874	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=14856)[0m 2021-10-26 15:08:58,946	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=14815)[0m 2021-10-26 15:08:58,946	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=14808)[0m 2021-10-26 15:08:59,002	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
[2m[36m(pid=14798)[0m 2021-10-26 15:08:59,024	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
2021-10-26 15:11:50,201	INFO tune.py:545 -- Total run time: 184.61 seconds (183.67 seconds for the tuning loop).
The seed = 124
The random seed = 834

<class 'environments.edge_cloud.simulation.environment.EdgeCloudEnv1'>
start training
== Status ==
Memory usage on this node: 67.4/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/502.21 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 PENDING)
+-------------------------------+----------+-------+--------+--------------------+
| Trial name                    | status   | loc   |     lr |   train_batch_size |
|-------------------------------+----------+-------+--------+--------------------|
| PPO_EdgeCloudEnv1_3b97f_00000 | PENDING  |       | 0.0001 |               3000 |
| PPO_EdgeCloudEnv1_3b97f_00001 | PENDING  |       | 0.001  |               3000 |
+-------------------------------+----------+-------+--------+--------------------+


Result for PPO_EdgeCloudEnv1_3b97f_00000:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-09-40
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 01b3c52d5ed246999b6028f856a0bb27
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5996981921496691
          entropy_coeff: 0.0
          kl: 0.008815318613239533
          policy_loss: 0.0014780368991531767
          total_loss: 17552714.26891892
          vf_explained_var: 0.0035156048834323883
          vf_loss: 17552713.961711712
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.59666666666668
    ram_util_percent: 9.190000000000003
  pid: 14815
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.09843150711664117
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.384858550058116
    mean_inference_ms: 1.7884700309644597
    mean_raw_obs_processing_ms: 1.6010341855878878
  time_since_restore: 41.74868869781494
  time_this_iter_s: 41.74868869781494
  time_total_s: 41.74868869781494
  timers:
    learn_throughput: 159.598
    learn_time_ms: 19737.033
    sample_throughput: 143.241
    sample_time_ms: 21990.95
    update_time_ms: 5.564
  timestamp: 1635257380
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: 3b97f_00000
  
== Status ==
Memory usage on this node: 69.9/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/502.21 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_3b97f_00000 | RUNNING  | 10.13.39.107:14815 | 0.0001 |               3000 |      1 |          41.7487 | 3150 |    24082 |              27658.6 |              19975.5 |                 30 |
| PPO_EdgeCloudEnv1_3b97f_00001 | RUNNING  |                    | 0.001  |               3000 |        |                  |      |          |                      |                      |                    |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_3b97f_00001:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-09-40
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 4ba0307eb06d434294b003df15e7e149
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.001
          entropy: 1.513871910443177
          entropy_coeff: 0.0
          kl: 0.11704072306168711
          policy_loss: 0.05776758837566852
          total_loss: 17551071.286486488
          vf_explained_var: 0.019300125539302826
          vf_loss: 17551070.964864865
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.6
    ram_util_percent: 9.190000000000003
  pid: 14856
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.1005741004520664
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.491979073042355
    mean_inference_ms: 1.7929321234653195
    mean_raw_obs_processing_ms: 1.6648656025930366
  time_since_restore: 41.86428713798523
  time_this_iter_s: 41.86428713798523
  time_total_s: 41.86428713798523
  timers:
    learn_throughput: 158.571
    learn_time_ms: 19864.889
    sample_throughput: 143.381
    sample_time_ms: 21969.38
    update_time_ms: 3.47
  timestamp: 1635257380
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: 3b97f_00001
  
Result for PPO_EdgeCloudEnv1_3b97f_00000:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.409523809523808
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 2
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7899.162126828118
    Social Welfare (Random Allocation)_mean: 5457.097407951896
    Social Welfare (Random Allocation)_min: 3888.1292006071553
    Social Welfare_max: 9206.785565279099
    Social Welfare_mean: 7999.137798974094
    Social Welfare_min: 6714.454867620475
  date: 2021-10-26_15-10-21
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27620.3566958373
  episode_reward_mean: 23997.413396922282
  episode_reward_min: 20143.364602861435
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 01b3c52d5ed246999b6028f856a0bb27
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.584746137556729
          entropy_coeff: 0.0
          kl: 0.018195911197172728
          policy_loss: 0.004404350303557621
          total_loss: 16873026.68738739
          vf_explained_var: 0.014319381676614285
          vf_loss: 16873026.40135135
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 48.37586206896552
    ram_util_percent: 9.253448275862072
  pid: 14815
  policy_reward_max:
    default: 9206.785565279099
  policy_reward_mean:
    default: 7999.137798974094
  policy_reward_min:
    default: 6714.454867620475
  sampler_perf:
    mean_action_processing_ms: 0.09571986005572837
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.815220397961316
    mean_inference_ms: 1.7147035848328653
    mean_raw_obs_processing_ms: 1.5864972743035115
  time_since_restore: 82.30178499221802
  time_this_iter_s: 40.553096294403076
  time_total_s: 82.30178499221802
  timers:
    learn_throughput: 159.551
    learn_time_ms: 19742.907
    sample_throughput: 147.288
    sample_time_ms: 21386.61
    update_time_ms: 4.533
  timestamp: 1635257421
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: 3b97f_00000
  
== Status ==
Memory usage on this node: 69.7/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/502.21 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_0_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_5_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_5_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_1_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_3_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_0_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_1_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_4_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_4_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_2_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_2_40789f3c30819e1f483d941943162b49, 0.0/6.0 CPU_group_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_3_40789f3c30819e1f483d941943162b49)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_3b97f_00000 | RUNNING  | 10.13.39.107:14815 | 0.0001 |               3000 |      2 |          82.3018 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_3b97f_00001 | RUNNING  | 10.13.39.107:14856 | 0.001  |               3000 |      1 |          41.8643 | 3150 |  24082   |              27658.6 |              19975.5 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_3b97f_00001:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 28.60952380952381
    Allocated Tasks Number_min: 25
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.504761904761905
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7886.312692320824
    Social Welfare (Random Allocation)_mean: 5454.690507335335
    Social Welfare (Random Allocation)_min: 3993.6764038328247
    Social Welfare_max: 8857.690324940027
    Social Welfare_mean: 7595.790692926532
    Social Welfare_min: 6212.450802427609
  date: 2021-10-26_15-10-24
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 26573.070974820075
  episode_reward_mean: 22787.372078779597
  episode_reward_min: 18637.3524072828
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 4ba0307eb06d434294b003df15e7e149
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.001
          entropy: 1.2516942950142074
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15826879244482328
          total_loss: .inf
          vf_explained_var: 0.08230109512805939
          vf_loss: 14567135.024324324
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 48.26451612903226
    ram_util_percent: 9.250000000000005
  pid: 14856
  policy_reward_max:
    default: 8857.690324940027
  policy_reward_mean:
    default: 7595.790692926533
  policy_reward_min:
    default: 6212.450802427609
  sampler_perf:
    mean_action_processing_ms: 0.09810234420740065
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.07585917267886
    mean_inference_ms: 1.731077666135178
    mean_raw_obs_processing_ms: 1.6397585479349113
  time_since_restore: 84.8406994342804
  time_this_iter_s: 42.976412296295166
  time_total_s: 84.8406994342804
  timers:
    learn_throughput: 153.992
    learn_time_ms: 20455.555
    sample_throughput: 143.592
    sample_time_ms: 21937.164
    update_time_ms: 3.683
  timestamp: 1635257424
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: 3b97f_00001
  
Result for PPO_EdgeCloudEnv1_3b97f_00000:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.419047619047618
    Allocated Tasks Number_min: 27
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.828571428571428
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7500.308337068168
    Social Welfare (Random Allocation)_mean: 5593.45734795943
    Social Welfare (Random Allocation)_min: 3758.2663214270156
    Social Welfare_max: 9294.820375261532
    Social Welfare_mean: 8038.417341800684
    Social Welfare_min: 6445.078494603251
  date: 2021-10-26_15-11-02
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27884.4611257846
  episode_reward_mean: 24115.252025402053
  episode_reward_min: 19335.23548380974
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 01b3c52d5ed246999b6028f856a0bb27
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5625350365767607
          entropy_coeff: 0.0
          kl: 0.023187605126125617
          policy_loss: 0.008069554482049704
          total_loss: 16464452.908108108
          vf_explained_var: 0.03559638187289238
          vf_loss: 16464452.673423423
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.833898305084745
    ram_util_percent: 9.210169491525425
  pid: 14815
  policy_reward_max:
    default: 9294.820375261532
  policy_reward_mean:
    default: 8038.417341800683
  policy_reward_min:
    default: 6445.078494603251
  sampler_perf:
    mean_action_processing_ms: 0.09494780989817876
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.67301393425193
    mean_inference_ms: 1.694254191825782
    mean_raw_obs_processing_ms: 1.5989435973588526
  time_since_restore: 123.38813424110413
  time_this_iter_s: 41.08634924888611
  time_total_s: 123.38813424110413
  timers:
    learn_throughput: 158.852
    learn_time_ms: 19829.811
    sample_throughput: 148.036
    sample_time_ms: 21278.671
    update_time_ms: 4.068
  timestamp: 1635257462
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: 3b97f_00000
  
== Status ==
Memory usage on this node: 69.7/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/502.21 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_3_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_5_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_4_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_1_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_3_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_1_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_2_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_5_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_0_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_4_17871050a3dbbf27832f7a51d01270be, 0.0/6.0 CPU_group_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_0_40789f3c30819e1f483d941943162b49, 0.0/6.0 CPU_group_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_2_17871050a3dbbf27832f7a51d01270be)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_3b97f_00000 | RUNNING  | 10.13.39.107:14815 | 0.0001 |               3000 |      3 |         123.388  | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_3b97f_00001 | RUNNING  | 10.13.39.107:14856 | 0.001  |               3000 |      2 |          84.8407 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_3b97f_00001:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.533333333333335
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 6.20952380952381
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7561.037728969207
    Social Welfare (Random Allocation)_mean: 5639.056399037374
    Social Welfare (Random Allocation)_min: 3444.0735201120983
    Social Welfare_max: 9393.3159210423
    Social Welfare_mean: 8191.429139103084
    Social Welfare_min: 6668.9270033924095
  date: 2021-10-26_15-11-06
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28179.947763126926
  episode_reward_mean: 24574.287417309253
  episode_reward_min: 20006.78101017722
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 4ba0307eb06d434294b003df15e7e149
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.4500000000000001
          cur_lr: 0.001
          entropy: 0.9873753228405804
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15913675058977092
          total_loss: .inf
          vf_explained_var: 0.16473977267742157
          vf_loss: 16097216.598648649
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.89016393442623
    ram_util_percent: 9.208196721311477
  pid: 14856
  policy_reward_max:
    default: 9393.3159210423
  policy_reward_mean:
    default: 8191.429139103086
  policy_reward_min:
    default: 6668.9270033924095
  sampler_perf:
    mean_action_processing_ms: 0.09661817727172142
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.80410138618877
    mean_inference_ms: 1.7031346850140519
    mean_raw_obs_processing_ms: 1.6211364207477053
  time_since_restore: 127.5356662273407
  time_this_iter_s: 42.6949667930603
  time_total_s: 127.5356662273407
  timers:
    learn_throughput: 151.281
    learn_time_ms: 20822.15
    sample_throughput: 145.401
    sample_time_ms: 21664.164
    update_time_ms: 3.524
  timestamp: 1635257466
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: 3b97f_00001
  
Result for PPO_EdgeCloudEnv1_3b97f_00000:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.64761904761905
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7595.848139463799
    Social Welfare (Random Allocation)_mean: 5713.912731429197
    Social Welfare (Random Allocation)_min: 4210.0886792356905
    Social Welfare_max: 9356.013150952798
    Social Welfare_mean: 8157.091040975737
    Social Welfare_min: 6596.6455070559105
  date: 2021-10-26_15-11-43
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28068.039452858404
  episode_reward_mean: 24471.273122927214
  episode_reward_min: 19789.936521167747
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 01b3c52d5ed246999b6028f856a0bb27
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.00010000000000000003
          entropy: 1.545704576507345
          entropy_coeff: 0.0
          kl: 0.0212652327241367
          policy_loss: 0.007853564555307868
          total_loss: 16564141.26036036
          vf_explained_var: 0.04438931494951248
          vf_loss: 16564141.00045045
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.66206896551724
    ram_util_percent: 9.086206896551726
  pid: 14815
  policy_reward_max:
    default: 9356.013150952798
  policy_reward_mean:
    default: 8157.091040975736
  policy_reward_min:
    default: 6596.6455070559105
  sampler_perf:
    mean_action_processing_ms: 0.09427386491556858
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.561189071189222
    mean_inference_ms: 1.6805265972132908
    mean_raw_obs_processing_ms: 1.5930649592071622
  time_since_restore: 164.4703414440155
  time_this_iter_s: 41.08220720291138
  time_total_s: 164.4703414440155
  timers:
    learn_throughput: 158.214
    learn_time_ms: 19909.768
    sample_throughput: 148.671
    sample_time_ms: 21187.699
    update_time_ms: 3.774
  timestamp: 1635257503
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: 3b97f_00000
  
== Status ==
Memory usage on this node: 68.9/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/502.21 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_3_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_1_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_5_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_0_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_3_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_4_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_0_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_1_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_2_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_5_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_2_40789f3c30819e1f483d941943162b49, 0.0/6.0 CPU_group_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_4_40789f3c30819e1f483d941943162b49, 0.0/6.0 CPU_group_40789f3c30819e1f483d941943162b49)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_3b97f_00000 | RUNNING  | 10.13.39.107:14815 | 0.0001 |               3000 |      4 |          164.47  | 12600 |  24471.3 |              28068   |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_3b97f_00001 | RUNNING  | 10.13.39.107:14856 | 0.001  |               3000 |      3 |          127.536 |  9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_3b97f_00001:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.79047619047619
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 15
    Bad Allocations Number_mean: 7.104761904761904
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7226.507746909067
    Social Welfare (Random Allocation)_mean: 5645.498463884971
    Social Welfare (Random Allocation)_min: 4284.401252245399
    Social Welfare_max: 9260.343498766093
    Social Welfare_mean: 8414.514033610567
    Social Welfare_min: 6964.4019115518095
  date: 2021-10-26_15-11-49
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27781.03049629827
  episode_reward_mean: 25243.5421008317
  episode_reward_min: 20893.205734655414
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 4ba0307eb06d434294b003df15e7e149
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.6749999999999998
          cur_lr: 0.001
          entropy: 0.9576918035449724
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.16871869819425467
          total_loss: .inf
          vf_explained_var: 0.1990945041179657
          vf_loss: 16136426.923873873
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 46.708196721311474
    ram_util_percent: 9.077049180327869
  pid: 14856
  policy_reward_max:
    default: 9260.343498766093
  policy_reward_mean:
    default: 8414.514033610567
  policy_reward_min:
    default: 6964.4019115518095
  sampler_perf:
    mean_action_processing_ms: 0.09598249672235641
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.78543370832105
    mean_inference_ms: 1.6889546987131823
    mean_raw_obs_processing_ms: 1.6155744156918794
  time_since_restore: 170.37891936302185
  time_this_iter_s: 42.84325313568115
  time_total_s: 170.37891936302185
  timers:
    learn_throughput: 149.828
    learn_time_ms: 21024.078
    sample_throughput: 146.198
    sample_time_ms: 21546.064
    update_time_ms: 3.155
  timestamp: 1635257509
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: 3b97f_00001
  
== Status ==
Memory usage on this node: 69.0/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 6.0/64 CPUs, 0/0 GPUs, 0.0/502.21 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_2_40789f3c30819e1f483d941943162b49, 0.0/6.0 CPU_group_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_3_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_1_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_4_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_3_40789f3c30819e1f483d941943162b49, 0.0/6.0 CPU_group_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_0_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_5_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_0_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_1_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_5_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_4_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_2_17871050a3dbbf27832f7a51d01270be)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_3b97f_00001 | RUNNING    | 10.13.39.107:14856 | 0.001  |               3000 |      4 |          170.379 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
| PPO_EdgeCloudEnv1_3b97f_00000 | TERMINATED |                    | 0.0001 |               3000 |      4 |          164.47  | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 69.0/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/502.21 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_2_40789f3c30819e1f483d941943162b49, 0.0/6.0 CPU_group_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_3_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_1_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_4_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_3_40789f3c30819e1f483d941943162b49, 0.0/6.0 CPU_group_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_0_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_5_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_0_17871050a3dbbf27832f7a51d01270be, 0.0/1.0 CPU_group_1_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_5_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_4_40789f3c30819e1f483d941943162b49, 0.0/1.0 CPU_group_2_17871050a3dbbf27832f7a51d01270be)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 TERMINATED)
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc   |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_3b97f_00000 | TERMINATED |       | 0.0001 |               3000 |      4 |          164.47  | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_3b97f_00001 | TERMINATED |       | 0.001  |               3000 |      4 |          170.379 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x2b49e41d4e48>
2021-10-26 15:12:37,029	INFO services.py:1247 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
[2m[36m(pid=17367)[0m 2021-10-26 15:13:04,519	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=17385)[0m 2021-10-26 15:13:04,519	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=17388)[0m 2021-10-26 15:13:11,670	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17337)[0m 2021-10-26 15:13:11,669	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17383)[0m 2021-10-26 15:13:11,670	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17377)[0m 2021-10-26 15:13:11,670	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17381)[0m 2021-10-26 15:13:11,669	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17360)[0m 2021-10-26 15:13:11,670	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17371)[0m 2021-10-26 15:13:11,669	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17393)[0m 2021-10-26 15:13:11,669	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17361)[0m 2021-10-26 15:13:11,669	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17343)[0m 2021-10-26 15:13:11,669	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17367)[0m 2021-10-26 15:13:12,161	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17385)[0m 2021-10-26 15:13:12,161	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=17367)[0m 2021-10-26 15:13:12,230	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=17385)[0m 2021-10-26 15:13:12,230	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=17393)[0m 2021-10-26 15:13:12,287	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
[2m[36m(pid=17361)[0m 2021-10-26 15:13:12,291	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
2021-10-26 15:16:04,881	INFO tune.py:545 -- Total run time: 199.89 seconds (198.72 seconds for the tuning loop).
The seed = 124
The random seed = 822

<class 'environments.edge_cloud.simulation.environment.EdgeCloudEnv1'>
start training
== Status ==
Memory usage on this node: 67.8/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/499.46 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 PENDING)
+-------------------------------+----------+-------+--------+--------------------+
| Trial name                    | status   | loc   |     lr |   train_batch_size |
|-------------------------------+----------+-------+--------+--------------------|
| PPO_EdgeCloudEnv1_ca490_00000 | PENDING  |       | 0.0001 |               3000 |
| PPO_EdgeCloudEnv1_ca490_00001 | PENDING  |       | 0.001  |               3000 |
+-------------------------------+----------+-------+--------+--------------------+


Result for PPO_EdgeCloudEnv1_ca490_00000:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-13-52
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: ecdaf544decd4fb982a469cff9fe21fa
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5996981921496691
          entropy_coeff: 0.0
          kl: 0.008815318613239533
          policy_loss: 0.0014780368991531767
          total_loss: 17552714.26891892
          vf_explained_var: 0.0035156048834323883
          vf_loss: 17552713.961711712
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.946551724137926
    ram_util_percent: 8.972413793103447
  pid: 17385
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.0982565660673163
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.57719305615795
    mean_inference_ms: 1.7436310908684827
    mean_raw_obs_processing_ms: 1.590177638783886
  time_since_restore: 40.009729862213135
  time_this_iter_s: 40.009729862213135
  time_total_s: 40.009729862213135
  timers:
    learn_throughput: 167.616
    learn_time_ms: 18792.934
    sample_throughput: 148.596
    sample_time_ms: 21198.417
    update_time_ms: 3.466
  timestamp: 1635257632
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: ca490_00000
  
== Status ==
Memory usage on this node: 68.4/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.46 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_ca490_00000 | RUNNING  | 10.13.39.107:17385 | 0.0001 |               3000 |      1 |          40.0097 | 3150 |    24082 |              27658.6 |              19975.5 |                 30 |
| PPO_EdgeCloudEnv1_ca490_00001 | RUNNING  |                    | 0.001  |               3000 |        |                  |      |          |                      |                      |                    |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_ca490_00001:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-13-54
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 20a0abd8af414fcfbf26be4530c02fb4
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.001
          entropy: 1.513871910443177
          entropy_coeff: 0.0
          kl: 0.11704072306168711
          policy_loss: 0.05776758837566852
          total_loss: 17551071.286486488
          vf_explained_var: 0.019300125539302826
          vf_loss: 17551070.964864865
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.98032786885246
    ram_util_percent: 8.978688524590165
  pid: 17367
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.1032477135514684
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.067649771785586
    mean_inference_ms: 1.817616796720236
    mean_raw_obs_processing_ms: 1.665767361358304
  time_since_restore: 42.16209864616394
  time_this_iter_s: 42.16209864616394
  time_total_s: 42.16209864616394
  timers:
    learn_throughput: 159.364
    learn_time_ms: 19766.028
    sample_throughput: 140.847
    sample_time_ms: 22364.677
    update_time_ms: 4.472
  timestamp: 1635257634
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: ca490_00001
  
Result for PPO_EdgeCloudEnv1_ca490_00000:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.409523809523808
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 2
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7899.162126828118
    Social Welfare (Random Allocation)_mean: 5457.097407951896
    Social Welfare (Random Allocation)_min: 3888.1292006071553
    Social Welfare_max: 9206.785565279099
    Social Welfare_mean: 7999.137798974094
    Social Welfare_min: 6714.454867620475
  date: 2021-10-26_15-14-33
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27620.3566958373
  episode_reward_mean: 23997.413396922282
  episode_reward_min: 20143.364602861435
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: ecdaf544decd4fb982a469cff9fe21fa
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.584746137556729
          entropy_coeff: 0.0
          kl: 0.018195911197172728
          policy_loss: 0.004404350303557621
          total_loss: 16873026.68738739
          vf_explained_var: 0.014319381676614285
          vf_loss: 16873026.40135135
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 48.089655172413785
    ram_util_percent: 9.113793103448275
  pid: 17385
  policy_reward_max:
    default: 9206.785565279099
  policy_reward_mean:
    default: 7999.137798974094
  policy_reward_min:
    default: 6714.454867620475
  sampler_perf:
    mean_action_processing_ms: 0.09682036694035845
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.33602794402181
    mean_inference_ms: 1.6831814722821978
    mean_raw_obs_processing_ms: 1.5938811411846256
  time_since_restore: 80.73590898513794
  time_this_iter_s: 40.726179122924805
  time_total_s: 80.73590898513794
  timers:
    learn_throughput: 164.969
    learn_time_ms: 19094.487
    sample_throughput: 148.2
    sample_time_ms: 21255.01
    update_time_ms: 3.281
  timestamp: 1635257673
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: ca490_00000
  
== Status ==
Memory usage on this node: 69.9/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.46 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_5_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_4_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_5_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_1_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_4_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_0_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_2_b367b38dd0d110f0fbc281ae1640c96a, 0.0/6.0 CPU_group_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_0_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_3_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_2_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_3_d0d40b0d959bb212860200f0fd111723, 0.0/6.0 CPU_group_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_1_d0d40b0d959bb212860200f0fd111723)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_ca490_00000 | RUNNING  | 10.13.39.107:17385 | 0.0001 |               3000 |      2 |          80.7359 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_ca490_00001 | RUNNING  | 10.13.39.107:17367 | 0.001  |               3000 |      1 |          42.1621 | 3150 |  24082   |              27658.6 |              19975.5 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_ca490_00001:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 28.60952380952381
    Allocated Tasks Number_min: 25
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.504761904761905
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7886.312692320824
    Social Welfare (Random Allocation)_mean: 5454.690507335335
    Social Welfare (Random Allocation)_min: 3993.6764038328247
    Social Welfare_max: 8857.690324940027
    Social Welfare_mean: 7595.790692926532
    Social Welfare_min: 6212.450802427609
  date: 2021-10-26_15-14-37
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 26573.070974820075
  episode_reward_mean: 22787.372078779597
  episode_reward_min: 18637.3524072828
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 20a0abd8af414fcfbf26be4530c02fb4
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.001
          entropy: 1.2516942950142074
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15826879244482328
          total_loss: .inf
          vf_explained_var: 0.08230109512805939
          vf_loss: 14567135.024324324
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 48.026666666666664
    ram_util_percent: 9.123333333333337
  pid: 17367
  policy_reward_max:
    default: 8857.690324940027
  policy_reward_mean:
    default: 7595.790692926533
  policy_reward_min:
    default: 6212.450802427609
  sampler_perf:
    mean_action_processing_ms: 0.09911432803197102
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.625455847247828
    mean_inference_ms: 1.7285302364098276
    mean_raw_obs_processing_ms: 1.6344077241127686
  time_since_restore: 84.7652063369751
  time_this_iter_s: 42.60310769081116
  time_total_s: 84.7652063369751
  timers:
    learn_throughput: 153.476
    learn_time_ms: 20524.38
    sample_throughput: 144.283
    sample_time_ms: 21832.11
    update_time_ms: 3.927
  timestamp: 1635257677
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: ca490_00001
  
Result for PPO_EdgeCloudEnv1_ca490_00000:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.419047619047618
    Allocated Tasks Number_min: 27
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.828571428571428
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7500.308337068168
    Social Welfare (Random Allocation)_mean: 5593.45734795943
    Social Welfare (Random Allocation)_min: 3758.2663214270156
    Social Welfare_max: 9294.820375261532
    Social Welfare_mean: 8038.417341800684
    Social Welfare_min: 6445.078494603251
  date: 2021-10-26_15-15-14
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27884.4611257846
  episode_reward_mean: 24115.252025402053
  episode_reward_min: 19335.23548380974
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: ecdaf544decd4fb982a469cff9fe21fa
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5625350365767607
          entropy_coeff: 0.0
          kl: 0.023187605126125617
          policy_loss: 0.008069554482049704
          total_loss: 16464452.908108108
          vf_explained_var: 0.03559638187289238
          vf_loss: 16464452.673423423
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.38305084745763
    ram_util_percent: 9.1271186440678
  pid: 17385
  policy_reward_max:
    default: 9294.820375261532
  policy_reward_mean:
    default: 8038.417341800683
  policy_reward_min:
    default: 6445.078494603251
  sampler_perf:
    mean_action_processing_ms: 0.09552699935808186
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.541358261874965
    mean_inference_ms: 1.662984618051288
    mean_raw_obs_processing_ms: 1.600390398458222
  time_since_restore: 122.23334527015686
  time_this_iter_s: 41.49743628501892
  time_total_s: 122.23334527015686
  timers:
    learn_throughput: 163.114
    learn_time_ms: 19311.65
    sample_throughput: 147.108
    sample_time_ms: 21412.837
    update_time_ms: 3.208
  timestamp: 1635257714
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: ca490_00000
  
== Status ==
Memory usage on this node: 69.4/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.46 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_0_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_2_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_4_d0d40b0d959bb212860200f0fd111723, 0.0/6.0 CPU_group_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_4_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_5_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_2_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_3_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_1_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_0_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_3_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_1_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_5_d0d40b0d959bb212860200f0fd111723, 0.0/6.0 CPU_group_b367b38dd0d110f0fbc281ae1640c96a)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_ca490_00000 | RUNNING  | 10.13.39.107:17385 | 0.0001 |               3000 |      3 |         122.233  | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_ca490_00001 | RUNNING  | 10.13.39.107:17367 | 0.001  |               3000 |      2 |          84.7652 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_ca490_00001:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.533333333333335
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 6.20952380952381
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7561.037728969207
    Social Welfare (Random Allocation)_mean: 5639.056399037374
    Social Welfare (Random Allocation)_min: 3444.0735201120983
    Social Welfare_max: 9393.3159210423
    Social Welfare_mean: 8191.429139103084
    Social Welfare_min: 6668.9270033924095
  date: 2021-10-26_15-15-20
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28179.947763126926
  episode_reward_mean: 24574.287417309253
  episode_reward_min: 20006.78101017722
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 20a0abd8af414fcfbf26be4530c02fb4
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.4500000000000001
          cur_lr: 0.001
          entropy: 0.9873753228405804
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15913675058977092
          total_loss: .inf
          vf_explained_var: 0.16473977267742157
          vf_loss: 16097216.598648649
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.29206349206349
    ram_util_percent: 9.123809523809529
  pid: 17367
  policy_reward_max:
    default: 9393.3159210423
  policy_reward_mean:
    default: 8191.429139103086
  policy_reward_min:
    default: 6668.9270033924095
  sampler_perf:
    mean_action_processing_ms: 0.09772889769184469
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.768939045987263
    mean_inference_ms: 1.7046373146416207
    mean_raw_obs_processing_ms: 1.6595796073699738
  time_since_restore: 128.59811544418335
  time_this_iter_s: 43.83290910720825
  time_total_s: 128.59811544418335
  timers:
    learn_throughput: 150.254
    learn_time_ms: 20964.501
    sample_throughput: 143.987
    sample_time_ms: 21876.989
    update_time_ms: 3.717
  timestamp: 1635257720
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: ca490_00001
  
== Status ==
Memory usage on this node: 69.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.46 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_2_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_4_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_4_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_3_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_0_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_1_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_2_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_5_b367b38dd0d110f0fbc281ae1640c96a, 0.0/6.0 CPU_group_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_3_b367b38dd0d110f0fbc281ae1640c96a, 0.0/6.0 CPU_group_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_5_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_0_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_1_d0d40b0d959bb212860200f0fd111723)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_ca490_00000 | RUNNING  | 10.13.39.107:17385 | 0.0001 |               3000 |      3 |          122.233 | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_ca490_00001 | RUNNING  | 10.13.39.107:17367 | 0.001  |               3000 |      3 |          128.598 | 9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_ca490_00000:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.64761904761905
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7595.848139463799
    Social Welfare (Random Allocation)_mean: 5713.912731429197
    Social Welfare (Random Allocation)_min: 4210.0886792356905
    Social Welfare_max: 9356.013150952798
    Social Welfare_mean: 8157.091040975737
    Social Welfare_min: 6596.6455070559105
  date: 2021-10-26_15-15-55
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28068.039452858404
  episode_reward_mean: 24471.273122927214
  episode_reward_min: 19789.936521167747
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: ecdaf544decd4fb982a469cff9fe21fa
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.00010000000000000003
          entropy: 1.545704576507345
          entropy_coeff: 0.0
          kl: 0.0212652327241367
          policy_loss: 0.007853564555307868
          total_loss: 16564141.26036036
          vf_explained_var: 0.04438931494951248
          vf_loss: 16564141.00045045
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.76896551724138
    ram_util_percent: 9.201724137931036
  pid: 17385
  policy_reward_max:
    default: 9356.013150952798
  policy_reward_mean:
    default: 8157.091040975736
  policy_reward_min:
    default: 6596.6455070559105
  sampler_perf:
    mean_action_processing_ms: 0.09498999072464151
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.476613782786607
    mean_inference_ms: 1.6519119038746406
    mean_raw_obs_processing_ms: 1.598636747494145
  time_since_restore: 162.89590859413147
  time_this_iter_s: 40.66256332397461
  time_total_s: 162.89590859413147
  timers:
    learn_throughput: 162.626
    learn_time_ms: 19369.62
    sample_throughput: 147.652
    sample_time_ms: 21333.95
    update_time_ms: 3.19
  timestamp: 1635257755
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: ca490_00000
  
== Status ==
Memory usage on this node: 69.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.46 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_2_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_4_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_4_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_3_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_0_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_1_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_2_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_5_b367b38dd0d110f0fbc281ae1640c96a, 0.0/6.0 CPU_group_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_3_b367b38dd0d110f0fbc281ae1640c96a, 0.0/6.0 CPU_group_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_5_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_0_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_1_d0d40b0d959bb212860200f0fd111723)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_ca490_00000 | RUNNING  | 10.13.39.107:17385 | 0.0001 |               3000 |      4 |          162.896 | 12600 |  24471.3 |              28068   |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_ca490_00001 | RUNNING  | 10.13.39.107:17367 | 0.001  |               3000 |      3 |          128.598 |  9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_ca490_00001:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.79047619047619
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 15
    Bad Allocations Number_mean: 7.104761904761904
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7226.507746909067
    Social Welfare (Random Allocation)_mean: 5645.498463884971
    Social Welfare (Random Allocation)_min: 4284.401252245399
    Social Welfare_max: 9260.343498766093
    Social Welfare_mean: 8414.514033610567
    Social Welfare_min: 6964.4019115518095
  date: 2021-10-26_15-16-04
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27781.03049629827
  episode_reward_mean: 25243.5421008317
  episode_reward_min: 20893.205734655414
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 20a0abd8af414fcfbf26be4530c02fb4
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.6749999999999998
          cur_lr: 0.001
          entropy: 0.9576918035449724
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.16871869819425467
          total_loss: .inf
          vf_explained_var: 0.1990945041179657
          vf_loss: 16136426.923873873
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 46.417741935483875
    ram_util_percent: 9.188709677419356
  pid: 17367
  policy_reward_max:
    default: 9260.343498766093
  policy_reward_mean:
    default: 8414.514033610567
  policy_reward_min:
    default: 6964.4019115518095
  sampler_perf:
    mean_action_processing_ms: 0.09708005442878455
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.68107126667972
    mean_inference_ms: 1.68992518811224
    mean_raw_obs_processing_ms: 1.665192301052991
  time_since_restore: 171.87816381454468
  time_this_iter_s: 43.28004837036133
  time_total_s: 171.87816381454468
  timers:
    learn_throughput: 149.512
    learn_time_ms: 21068.519
    sample_throughput: 143.982
    sample_time_ms: 21877.691
    update_time_ms: 3.511
  timestamp: 1635257764
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: ca490_00001
  
== Status ==
Memory usage on this node: 68.9/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 6.0/64 CPUs, 0/0 GPUs, 0.0/499.46 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_2_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_4_b367b38dd0d110f0fbc281ae1640c96a, 0.0/6.0 CPU_group_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_0_b367b38dd0d110f0fbc281ae1640c96a, 0.0/6.0 CPU_group_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_5_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_5_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_2_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_3_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_1_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_1_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_3_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_0_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_4_d0d40b0d959bb212860200f0fd111723)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_ca490_00001 | RUNNING    | 10.13.39.107:17367 | 0.001  |               3000 |      4 |          171.878 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
| PPO_EdgeCloudEnv1_ca490_00000 | TERMINATED |                    | 0.0001 |               3000 |      4 |          162.896 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 68.9/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/499.46 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_2_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_4_b367b38dd0d110f0fbc281ae1640c96a, 0.0/6.0 CPU_group_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_0_b367b38dd0d110f0fbc281ae1640c96a, 0.0/6.0 CPU_group_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_5_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_5_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_2_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_3_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_1_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_1_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_3_b367b38dd0d110f0fbc281ae1640c96a, 0.0/1.0 CPU_group_0_d0d40b0d959bb212860200f0fd111723, 0.0/1.0 CPU_group_4_d0d40b0d959bb212860200f0fd111723)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 TERMINATED)
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc   |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_ca490_00000 | TERMINATED |       | 0.0001 |               3000 |      4 |          162.896 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_ca490_00001 | TERMINATED |       | 0.001  |               3000 |      4 |          171.878 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x2b6308cf4358>
2021-10-26 15:16:33,957	INFO services.py:1247 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
[2m[36m(pid=19904)[0m 2021-10-26 15:16:52,379	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=19894)[0m 2021-10-26 15:16:52,379	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=19885)[0m 2021-10-26 15:16:58,470	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19897)[0m 2021-10-26 15:16:58,470	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19896)[0m 2021-10-26 15:16:58,469	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19889)[0m 2021-10-26 15:16:58,468	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19905)[0m 2021-10-26 15:16:58,468	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19903)[0m 2021-10-26 15:16:58,468	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19862)[0m 2021-10-26 15:16:58,469	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19872)[0m 2021-10-26 15:16:58,468	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19884)[0m 2021-10-26 15:16:58,468	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19891)[0m 2021-10-26 15:16:58,468	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19904)[0m 2021-10-26 15:16:58,807	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19894)[0m 2021-10-26 15:16:58,807	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=19904)[0m 2021-10-26 15:16:58,877	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=19894)[0m 2021-10-26 15:16:58,877	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=19885)[0m 2021-10-26 15:16:58,935	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
[2m[36m(pid=19897)[0m 2021-10-26 15:16:58,950	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
[2m[36m(pid=19885)[0m 2021-10-26 15:19:52,166	ERROR worker.py:421 -- SystemExit was raised from the worker
[2m[36m(pid=19885)[0m Traceback (most recent call last):
[2m[36m(pid=19885)[0m   File "python/ray/_raylet.pyx", line 530, in ray._raylet.execute_task
[2m[36m(pid=19885)[0m   File "python/ray/_raylet.pyx", line 534, in ray._raylet.execute_task
[2m[36m(pid=19885)[0m   File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task.function_executor
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/site-packages/ray/_private/function_manager.py", line 563, in actor_method_executor
[2m[36m(pid=19885)[0m     return method(__ray_actor, *args, **kwargs)
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/site-packages/ray/actor.py", line 1027, in __ray_terminate__
[2m[36m(pid=19885)[0m     ray.actor.exit_actor()
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/site-packages/ray/actor.py", line 1103, in exit_actor
[2m[36m(pid=19885)[0m     raise exit
[2m[36m(pid=19885)[0m SystemExit: 0
[2m[36m(pid=19885)[0m 
[2m[36m(pid=19885)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19885)[0m 
[2m[36m(pid=19885)[0m Traceback (most recent call last):
[2m[36m(pid=19885)[0m   File "python/ray/_raylet.pyx", line 632, in ray._raylet.task_execution_handler
[2m[36m(pid=19885)[0m   File "python/ray/_raylet.pyx", line 486, in ray._raylet.execute_task
[2m[36m(pid=19885)[0m   File "python/ray/_raylet.pyx", line 523, in ray._raylet.execute_task
[2m[36m(pid=19885)[0m   File "python/ray/includes/libcoreworker.pxi", line 33, in ray._raylet.ProfileEvent.__exit__
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/traceback.py", line 163, in format_exc
[2m[36m(pid=19885)[0m     return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/traceback.py", line 117, in format_exception
[2m[36m(pid=19885)[0m     type(value), value, tb, limit=limit).format(chain=chain))
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/traceback.py", line 497, in __init__
[2m[36m(pid=19885)[0m     capture_locals=capture_locals)
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/traceback.py", line 358, in extract
[2m[36m(pid=19885)[0m     f.line
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/traceback.py", line 282, in line
[2m[36m(pid=19885)[0m     self._line = linecache.getline(self.filename, self.lineno).strip()
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/linecache.py", line 16, in getline
[2m[36m(pid=19885)[0m     lines = getlines(filename, module_globals)
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/linecache.py", line 47, in getlines
[2m[36m(pid=19885)[0m     return updatecache(filename, module_globals)
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/linecache.py", line 136, in updatecache
[2m[36m(pid=19885)[0m     with tokenize.open(fullname) as fp:
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/tokenize.py", line 454, in open
[2m[36m(pid=19885)[0m     encoding, lines = detect_encoding(buffer.readline)
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/tokenize.py", line 423, in detect_encoding
[2m[36m(pid=19885)[0m     first = read_or_stop()
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/tokenize.py", line 381, in read_or_stop
[2m[36m(pid=19885)[0m     return readline()
[2m[36m(pid=19885)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/site-packages/ray/worker.py", line 418, in sigterm_handler
[2m[36m(pid=19885)[0m     sys.exit(1)
[2m[36m(pid=19885)[0m SystemExit: 1
[2m[36m(pid=19884)[0m 2021-10-26 15:19:52,166	ERROR worker.py:421 -- SystemExit was raised from the worker
[2m[36m(pid=19884)[0m Traceback (most recent call last):
[2m[36m(pid=19884)[0m   File "python/ray/_raylet.pyx", line 530, in ray._raylet.execute_task
[2m[36m(pid=19884)[0m   File "python/ray/_raylet.pyx", line 534, in ray._raylet.execute_task
[2m[36m(pid=19884)[0m   File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task.function_executor
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/site-packages/ray/_private/function_manager.py", line 563, in actor_method_executor
[2m[36m(pid=19884)[0m     return method(__ray_actor, *args, **kwargs)
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/site-packages/ray/actor.py", line 1027, in __ray_terminate__
[2m[36m(pid=19884)[0m     ray.actor.exit_actor()
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/site-packages/ray/actor.py", line 1103, in exit_actor
[2m[36m(pid=19884)[0m     raise exit
[2m[36m(pid=19884)[0m SystemExit: 0
[2m[36m(pid=19884)[0m 
[2m[36m(pid=19884)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19884)[0m 
[2m[36m(pid=19884)[0m Traceback (most recent call last):
[2m[36m(pid=19884)[0m   File "python/ray/_raylet.pyx", line 632, in ray._raylet.task_execution_handler
[2m[36m(pid=19884)[0m   File "python/ray/_raylet.pyx", line 486, in ray._raylet.execute_task
[2m[36m(pid=19884)[0m   File "python/ray/_raylet.pyx", line 523, in ray._raylet.execute_task
[2m[36m(pid=19884)[0m   File "python/ray/includes/libcoreworker.pxi", line 33, in ray._raylet.ProfileEvent.__exit__
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/traceback.py", line 163, in format_exc
[2m[36m(pid=19884)[0m     return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/traceback.py", line 117, in format_exception
[2m[36m(pid=19884)[0m     type(value), value, tb, limit=limit).format(chain=chain))
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/traceback.py", line 497, in __init__
[2m[36m(pid=19884)[0m     capture_locals=capture_locals)
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/traceback.py", line 358, in extract
[2m[36m(pid=19884)[0m     f.line
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/traceback.py", line 282, in line
[2m[36m(pid=19884)[0m     self._line = linecache.getline(self.filename, self.lineno).strip()
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/linecache.py", line 16, in getline
[2m[36m(pid=19884)[0m     lines = getlines(filename, module_globals)
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/linecache.py", line 47, in getlines
[2m[36m(pid=19884)[0m     return updatecache(filename, module_globals)
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/linecache.py", line 136, in updatecache
[2m[36m(pid=19884)[0m     with tokenize.open(fullname) as fp:
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/tokenize.py", line 454, in open
[2m[36m(pid=19884)[0m     encoding, lines = detect_encoding(buffer.readline)
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/tokenize.py", line 423, in detect_encoding
[2m[36m(pid=19884)[0m     first = read_or_stop()
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/tokenize.py", line 381, in read_or_stop
[2m[36m(pid=19884)[0m     return readline()
[2m[36m(pid=19884)[0m   File "/home/fb1n15/.conda/envs/jack/lib/python3.6/site-packages/ray/worker.py", line 418, in sigterm_handler
[2m[36m(pid=19884)[0m     sys.exit(1)
[2m[36m(pid=19884)[0m SystemExit: 1
2021-10-26 15:19:52,235	INFO tune.py:545 -- Total run time: 190.13 seconds (189.35 seconds for the tuning loop).
The seed = 124
The random seed = 165

<class 'environments.edge_cloud.simulation.environment.EdgeCloudEnv1'>
start training
== Status ==
Memory usage on this node: 68.3/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/499.87 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 PENDING)
+-------------------------------+----------+-------+--------+--------------------+
| Trial name                    | status   | loc   |     lr |   train_batch_size |
|-------------------------------+----------+-------+--------+--------------------|
| PPO_EdgeCloudEnv1_579da_00000 | PENDING  |       | 0.0001 |               3000 |
| PPO_EdgeCloudEnv1_579da_00001 | PENDING  |       | 0.001  |               3000 |
+-------------------------------+----------+-------+--------+--------------------+


Result for PPO_EdgeCloudEnv1_579da_00000:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-17-40
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 569fe2b4865742d3ae29e1ebcfdbb934
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5996981921496691
          entropy_coeff: 0.0
          kl: 0.008815318613239533
          policy_loss: 0.0014780368991531767
          total_loss: 17552714.26891892
          vf_explained_var: 0.0035156048834323883
          vf_loss: 17552713.961711712
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.67166666666666
    ram_util_percent: 9.223333333333331
  pid: 19904
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10031195336778642
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.84612097641934
    mean_inference_ms: 1.7724984799247536
    mean_raw_obs_processing_ms: 1.6059465907077213
  time_since_restore: 42.0143837928772
  time_this_iter_s: 42.0143837928772
  time_total_s: 42.0143837928772
  timers:
    learn_throughput: 157.403
    learn_time_ms: 20012.312
    sample_throughput: 143.317
    sample_time_ms: 21979.202
    update_time_ms: 4.861
  timestamp: 1635257860
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: 579da_00000
  
== Status ==
Memory usage on this node: 70.1/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.87 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_579da_00000 | RUNNING  | 10.13.39.107:19904 | 0.0001 |               3000 |      1 |          42.0144 | 3150 |    24082 |              27658.6 |              19975.5 |                 30 |
| PPO_EdgeCloudEnv1_579da_00001 | RUNNING  |                    | 0.001  |               3000 |        |                  |      |          |                      |                      |                    |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_579da_00001:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-17-41
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 08860e97d35b4dfa8073c647eb70657e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.001
          entropy: 1.513871910443177
          entropy_coeff: 0.0
          kl: 0.11704072306168711
          policy_loss: 0.05776758837566852
          total_loss: 17551071.286486488
          vf_explained_var: 0.019300125539302826
          vf_loss: 17551070.964864865
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.56065573770491
    ram_util_percent: 9.224590163934423
  pid: 19894
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.09925437238061485
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.2604475036476
    mean_inference_ms: 1.817214621228008
    mean_raw_obs_processing_ms: 1.6109647917105165
  time_since_restore: 42.37727737426758
  time_this_iter_s: 42.37727737426758
  time_total_s: 42.37727737426758
  timers:
    learn_throughput: 157.281
    learn_time_ms: 20027.786
    sample_throughput: 141.102
    sample_time_ms: 22324.212
    update_time_ms: 3.36
  timestamp: 1635257861
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: 579da_00001
  
Result for PPO_EdgeCloudEnv1_579da_00000:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.409523809523808
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 2
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7899.162126828118
    Social Welfare (Random Allocation)_mean: 5457.097407951896
    Social Welfare (Random Allocation)_min: 3888.1292006071553
    Social Welfare_max: 9206.785565279099
    Social Welfare_mean: 7999.137798974094
    Social Welfare_min: 6714.454867620475
  date: 2021-10-26_15-18-22
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27620.3566958373
  episode_reward_mean: 23997.413396922282
  episode_reward_min: 20143.364602861435
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 569fe2b4865742d3ae29e1ebcfdbb934
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.584746137556729
          entropy_coeff: 0.0
          kl: 0.018195911197172728
          policy_loss: 0.004404350303557621
          total_loss: 16873026.68738739
          vf_explained_var: 0.014319381676614285
          vf_loss: 16873026.40135135
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.276666666666664
    ram_util_percent: 9.239999999999997
  pid: 19904
  policy_reward_max:
    default: 9206.785565279099
  policy_reward_mean:
    default: 7999.137798974094
  policy_reward_min:
    default: 6714.454867620475
  sampler_perf:
    mean_action_processing_ms: 0.09791009677581423
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.584087784757315
    mean_inference_ms: 1.713213780680694
    mean_raw_obs_processing_ms: 1.605215723036207
  time_since_restore: 83.50855779647827
  time_this_iter_s: 41.494174003601074
  time_total_s: 83.50855779647827
  timers:
    learn_throughput: 157.554
    learn_time_ms: 19993.176
    sample_throughput: 144.902
    sample_time_ms: 21738.827
    update_time_ms: 3.988
  timestamp: 1635257902
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: 579da_00000
  
== Status ==
Memory usage on this node: 70.5/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.87 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_5_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_4_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_3_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_1_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_0_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_5_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_2_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_4_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_3_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/6.0 CPU_group_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_1_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_0_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_2_e5bfbdefbbf99d4a57bbd23ef5fe814b)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_579da_00000 | RUNNING  | 10.13.39.107:19904 | 0.0001 |               3000 |      2 |          83.5086 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_579da_00001 | RUNNING  | 10.13.39.107:19894 | 0.001  |               3000 |      1 |          42.3773 | 3150 |  24082   |              27658.6 |              19975.5 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_579da_00001:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 28.60952380952381
    Allocated Tasks Number_min: 25
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.504761904761905
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7886.312692320824
    Social Welfare (Random Allocation)_mean: 5454.690507335335
    Social Welfare (Random Allocation)_min: 3993.6764038328247
    Social Welfare_max: 8857.690324940027
    Social Welfare_mean: 7595.790692926532
    Social Welfare_min: 6212.450802427609
  date: 2021-10-26_15-18-24
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 26573.070974820075
  episode_reward_mean: 22787.372078779597
  episode_reward_min: 18637.3524072828
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 08860e97d35b4dfa8073c647eb70657e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.001
          entropy: 1.2516942950142074
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15826879244482328
          total_loss: .inf
          vf_explained_var: 0.08230109512805939
          vf_loss: 14567135.024324324
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 47.36557377049181
    ram_util_percent: 9.24262295081967
  pid: 19894
  policy_reward_max:
    default: 8857.690324940027
  policy_reward_mean:
    default: 7595.790692926533
  policy_reward_min:
    default: 6212.450802427609
  sampler_perf:
    mean_action_processing_ms: 0.0970377230058106
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.838326731718883
    mean_inference_ms: 1.7478909594591039
    mean_raw_obs_processing_ms: 1.6569144001657483
  time_since_restore: 85.09958028793335
  time_this_iter_s: 42.72230291366577
  time_total_s: 85.09958028793335
  timers:
    learn_throughput: 151.927
    learn_time_ms: 20733.7
    sample_throughput: 144.552
    sample_time_ms: 21791.499
    update_time_ms: 3.299
  timestamp: 1635257904
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: 579da_00001
  
Result for PPO_EdgeCloudEnv1_579da_00000:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.419047619047618
    Allocated Tasks Number_min: 27
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.828571428571428
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7500.308337068168
    Social Welfare (Random Allocation)_mean: 5593.45734795943
    Social Welfare (Random Allocation)_min: 3758.2663214270156
    Social Welfare_max: 9294.820375261532
    Social Welfare_mean: 8038.417341800684
    Social Welfare_min: 6445.078494603251
  date: 2021-10-26_15-19-03
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27884.4611257846
  episode_reward_mean: 24115.252025402053
  episode_reward_min: 19335.23548380974
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 569fe2b4865742d3ae29e1ebcfdbb934
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5625350365767607
          entropy_coeff: 0.0
          kl: 0.023187605126125617
          policy_loss: 0.008069554482049704
          total_loss: 16464452.908108108
          vf_explained_var: 0.03559638187289238
          vf_loss: 16464452.673423423
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 52.217241379310344
    ram_util_percent: 9.539655172413791
  pid: 19904
  policy_reward_max:
    default: 9294.820375261532
  policy_reward_mean:
    default: 8038.417341800683
  policy_reward_min:
    default: 6445.078494603251
  sampler_perf:
    mean_action_processing_ms: 0.09738865634992849
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.6222065694114
    mean_inference_ms: 1.7021821958561036
    mean_raw_obs_processing_ms: 1.6135341839964334
  time_since_restore: 124.49687075614929
  time_this_iter_s: 40.98831295967102
  time_total_s: 124.49687075614929
  timers:
    learn_throughput: 157.984
    learn_time_ms: 19938.756
    sample_throughput: 146.244
    sample_time_ms: 21539.374
    update_time_ms: 3.682
  timestamp: 1635257943
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: 579da_00000
  
== Status ==
Memory usage on this node: 75.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.87 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_1_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_5_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_4_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_2_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_3_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_0_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_3_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_1_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_2_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_5_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/6.0 CPU_group_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_4_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_0_e5bfbdefbbf99d4a57bbd23ef5fe814b)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_579da_00000 | RUNNING  | 10.13.39.107:19904 | 0.0001 |               3000 |      3 |         124.497  | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_579da_00001 | RUNNING  | 10.13.39.107:19894 | 0.001  |               3000 |      2 |          85.0996 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_579da_00001:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.533333333333335
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 6.20952380952381
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7561.037728969207
    Social Welfare (Random Allocation)_mean: 5639.056399037374
    Social Welfare (Random Allocation)_min: 3444.0735201120983
    Social Welfare_max: 9393.3159210423
    Social Welfare_mean: 8191.429139103084
    Social Welfare_min: 6668.9270033924095
  date: 2021-10-26_15-19-07
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28179.947763126926
  episode_reward_mean: 24574.287417309253
  episode_reward_min: 20006.78101017722
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 08860e97d35b4dfa8073c647eb70657e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.4500000000000001
          cur_lr: 0.001
          entropy: 0.9873753228405804
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15913675058977092
          total_loss: .inf
          vf_explained_var: 0.16473977267742157
          vf_loss: 16097216.598648649
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 52.61774193548387
    ram_util_percent: 9.593548387096776
  pid: 19894
  policy_reward_max:
    default: 9393.3159210423
  policy_reward_mean:
    default: 8191.429139103086
  policy_reward_min:
    default: 6668.9270033924095
  sampler_perf:
    mean_action_processing_ms: 0.09681382928179534
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.956443318609587
    mean_inference_ms: 1.7364192551119122
    mean_raw_obs_processing_ms: 1.6532517689866781
  time_since_restore: 128.6720485687256
  time_this_iter_s: 43.572468280792236
  time_total_s: 128.6720485687256
  timers:
    learn_throughput: 149.43
    learn_time_ms: 21080.082
    sample_throughput: 144.575
    sample_time_ms: 21788.042
    update_time_ms: 3.168
  timestamp: 1635257947
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: 579da_00001
  
Result for PPO_EdgeCloudEnv1_579da_00000:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.64761904761905
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7595.848139463799
    Social Welfare (Random Allocation)_mean: 5713.912731429197
    Social Welfare (Random Allocation)_min: 4210.0886792356905
    Social Welfare_max: 9356.013150952798
    Social Welfare_mean: 8157.091040975737
    Social Welfare_min: 6596.6455070559105
  date: 2021-10-26_15-19-45
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28068.039452858404
  episode_reward_mean: 24471.273122927214
  episode_reward_min: 19789.936521167747
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 569fe2b4865742d3ae29e1ebcfdbb934
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.00010000000000000003
          entropy: 1.545704576507345
          entropy_coeff: 0.0
          kl: 0.0212652327241367
          policy_loss: 0.007853564555307868
          total_loss: 16564141.26036036
          vf_explained_var: 0.04438931494951248
          vf_loss: 16564141.00045045
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 54.004999999999995
    ram_util_percent: 10.255
  pid: 19904
  policy_reward_max:
    default: 9356.013150952798
  policy_reward_mean:
    default: 8157.091040975736
  policy_reward_min:
    default: 6596.6455070559105
  sampler_perf:
    mean_action_processing_ms: 0.09723918298935429
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.63814037463722
    mean_inference_ms: 1.7038444638583257
    mean_raw_obs_processing_ms: 1.6177484224070546
  time_since_restore: 166.38448524475098
  time_this_iter_s: 41.887614488601685
  time_total_s: 166.38448524475098
  timers:
    learn_throughput: 157.848
    learn_time_ms: 19955.937
    sample_throughput: 145.699
    sample_time_ms: 21619.844
    update_time_ms: 3.497
  timestamp: 1635257985
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: 579da_00000
  
== Status ==
Memory usage on this node: 72.3/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/499.87 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_0_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_3_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/6.0 CPU_group_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_5_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_4_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_1_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/6.0 CPU_group_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_2_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_0_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_3_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_5_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_2_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_4_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_1_e5bfbdefbbf99d4a57bbd23ef5fe814b)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_579da_00000 | RUNNING  | 10.13.39.107:19904 | 0.0001 |               3000 |      4 |          166.384 | 12600 |  24471.3 |              28068   |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_579da_00001 | RUNNING  | 10.13.39.107:19894 | 0.001  |               3000 |      3 |          128.672 |  9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_579da_00001:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.79047619047619
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 15
    Bad Allocations Number_mean: 7.104761904761904
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7226.507746909067
    Social Welfare (Random Allocation)_mean: 5645.498463884971
    Social Welfare (Random Allocation)_min: 4284.401252245399
    Social Welfare_max: 9260.343498766093
    Social Welfare_mean: 8414.514033610567
    Social Welfare_min: 6964.4019115518095
  date: 2021-10-26_15-19-51
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27781.03049629827
  episode_reward_mean: 25243.5421008317
  episode_reward_min: 20893.205734655414
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 08860e97d35b4dfa8073c647eb70657e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.6749999999999998
          cur_lr: 0.001
          entropy: 0.9576918035449724
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.16871869819425467
          total_loss: .inf
          vf_explained_var: 0.1990945041179657
          vf_loss: 16136426.923873873
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 52.46507936507937
    ram_util_percent: 10.161904761904761
  pid: 19894
  policy_reward_max:
    default: 9260.343498766093
  policy_reward_mean:
    default: 8414.514033610567
  policy_reward_min:
    default: 6964.4019115518095
  sampler_perf:
    mean_action_processing_ms: 0.09655598750524888
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.991001101156776
    mean_inference_ms: 1.7268718021911835
    mean_raw_obs_processing_ms: 1.6540043319042408
  time_since_restore: 172.68564438819885
  time_this_iter_s: 44.01359581947327
  time_total_s: 172.68564438819885
  timers:
    learn_throughput: 147.884
    learn_time_ms: 21300.484
    sample_throughput: 144.171
    sample_time_ms: 21849.056
    update_time_ms: 3.17
  timestamp: 1635257991
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: 579da_00001
  
== Status ==
Memory usage on this node: 71.4/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 6.0/64 CPUs, 0/0 GPUs, 0.0/499.87 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_5_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_5_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_1_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_0_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_2_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_2_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_4_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_1_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_3_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_3_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/6.0 CPU_group_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_0_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_4_69b9167a2a6ad3fe8c8aa2799d71eba4)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_579da_00001 | RUNNING    | 10.13.39.107:19894 | 0.001  |               3000 |      4 |          172.686 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
| PPO_EdgeCloudEnv1_579da_00000 | TERMINATED |                    | 0.0001 |               3000 |      4 |          166.384 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 71.4/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/499.87 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_5_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_5_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_1_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_0_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_2_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_2_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_4_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_1_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_3_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_3_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/6.0 CPU_group_e5bfbdefbbf99d4a57bbd23ef5fe814b, 0.0/1.0 CPU_group_0_69b9167a2a6ad3fe8c8aa2799d71eba4, 0.0/1.0 CPU_group_4_69b9167a2a6ad3fe8c8aa2799d71eba4)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 TERMINATED)
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc   |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_579da_00000 | TERMINATED |       | 0.0001 |               3000 |      4 |          166.384 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_579da_00001 | TERMINATED |       | 0.001  |               3000 |      4 |          172.686 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x2b3db913fda0>
2021-10-26 15:20:08,956	INFO services.py:1247 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
[2m[36m(pid=26184)[0m 2021-10-26 15:20:24,506	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=26230)[0m 2021-10-26 15:20:24,506	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=26201)[0m 2021-10-26 15:20:31,064	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26217)[0m 2021-10-26 15:20:30,983	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26228)[0m 2021-10-26 15:20:30,982	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26234)[0m 2021-10-26 15:20:30,982	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26211)[0m 2021-10-26 15:20:30,982	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26184)[0m 2021-10-26 15:20:31,162	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26184)[0m 2021-10-26 15:20:31,232	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=26227)[0m 2021-10-26 15:20:31,267	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26214)[0m 2021-10-26 15:20:31,250	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26218)[0m 2021-10-26 15:20:31,279	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26221)[0m 2021-10-26 15:20:31,287	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26230)[0m 2021-10-26 15:20:31,357	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26230)[0m 2021-10-26 15:20:31,429	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=26225)[0m 2021-10-26 15:20:31,505	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=26201)[0m 2021-10-26 15:20:31,902	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
[2m[36m(pid=26227)[0m 2021-10-26 15:20:31,901	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
2021-10-26 15:42:56,989	INFO tune.py:545 -- Total run time: 1359.60 seconds (1358.43 seconds for the tuning loop).
The seed = 124
The random seed = 258

<class 'environments.edge_cloud.simulation.environment.EdgeCloudEnv1'>
start training
== Status ==
Memory usage on this node: 71.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/495.4 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 PENDING)
+-------------------------------+----------+-------+--------+--------------------+
| Trial name                    | status   | loc   |     lr |   train_batch_size |
|-------------------------------+----------+-------+--------+--------------------|
| PPO_EdgeCloudEnv1_d7ef0_00000 | PENDING  |       | 0.0001 |               3000 |
| PPO_EdgeCloudEnv1_d7ef0_00001 | PENDING  |       | 0.001  |               3000 |
+-------------------------------+----------+-------+--------+--------------------+


Result for PPO_EdgeCloudEnv1_d7ef0_00000:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-25-26
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 16144efa422a4568be282eb3f255c2fc
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5996981921496691
          entropy_coeff: 0.0
          kl: 0.008815318613239533
          policy_loss: 0.0014780368991531767
          total_loss: 17552714.26891892
          vf_explained_var: 0.0035156048834323883
          vf_loss: 17552713.961711712
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 42.5750593824228
    ram_util_percent: 9.74418052256532
  pid: 26230
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10254401979280162
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 416.5573169236706
    mean_inference_ms: 1.7952856284502758
    mean_raw_obs_processing_ms: 6.012757342137549
  time_since_restore: 294.8690195083618
  time_this_iter_s: 294.8690195083618
  time_total_s: 294.8690195083618
  timers:
    learn_throughput: 159.117
    learn_time_ms: 19796.738
    sample_throughput: 11.452
    sample_time_ms: 275052.301
    update_time_ms: 3.693
  timestamp: 1635258326
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: d7ef0_00000
  
== Status ==
Memory usage on this node: 74.2/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/495.4 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_d7ef0_00000 | RUNNING  | 10.13.39.107:26230 | 0.0001 |               3000 |      1 |          294.869 | 3150 |    24082 |              27658.6 |              19975.5 |                 30 |
| PPO_EdgeCloudEnv1_d7ef0_00001 | RUNNING  |                    | 0.001  |               3000 |        |                  |      |          |                      |                      |                    |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_d7ef0_00001:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-25-27
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: d8122bd7ec9d4c6493a4fb13e97960ae
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.001
          entropy: 1.513871910443177
          entropy_coeff: 0.0
          kl: 0.11704072306168711
          policy_loss: 0.05776758837566852
          total_loss: 17551071.286486488
          vf_explained_var: 0.019300125539302826
          vf_loss: 17551070.964864865
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 42.58175355450237
    ram_util_percent: 9.744075829383887
  pid: 26184
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10178281841489666
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 419.55438914654184
    mean_inference_ms: 1.8170649956221063
    mean_raw_obs_processing_ms: 6.092041608081943
  time_since_restore: 295.805214881897
  time_this_iter_s: 295.805214881897
  time_total_s: 295.805214881897
  timers:
    learn_throughput: 151.889
    learn_time_ms: 20738.763
    sample_throughput: 11.453
    sample_time_ms: 275046.396
    update_time_ms: 4.641
  timestamp: 1635258327
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: d7ef0_00001
  
Result for PPO_EdgeCloudEnv1_d7ef0_00001:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 28.60952380952381
    Allocated Tasks Number_min: 25
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.504761904761905
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7886.312692320824
    Social Welfare (Random Allocation)_mean: 5454.690507335335
    Social Welfare (Random Allocation)_min: 3993.6764038328247
    Social Welfare_max: 8857.690324940027
    Social Welfare_mean: 7595.790692926532
    Social Welfare_min: 6212.450802427609
  date: 2021-10-26_15-31-44
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 26573.070974820075
  episode_reward_mean: 22787.372078779597
  episode_reward_min: 18637.3524072828
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: d8122bd7ec9d4c6493a4fb13e97960ae
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.001
          entropy: 1.2516942950142074
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15826879244482328
          total_loss: .inf
          vf_explained_var: 0.08230109512805939
          vf_loss: 14567135.024324324
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 42.57732342007435
    ram_util_percent: 9.583457249070634
  pid: 26184
  policy_reward_max:
    default: 8857.690324940027
  policy_reward_mean:
    default: 7595.790692926533
  policy_reward_min:
    default: 6212.450802427609
  sampler_perf:
    mean_action_processing_ms: 0.10030400081819052
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 480.0270562319411
    mean_inference_ms: 1.8297587189761348
    mean_raw_obs_processing_ms: 6.673022813970943
  time_since_restore: 673.1439678668976
  time_this_iter_s: 377.3387529850006
  time_total_s: 673.1439678668976
  timers:
    learn_throughput: 149.874
    learn_time_ms: 21017.667
    sample_throughput: 9.983
    sample_time_ms: 315534.446
    update_time_ms: 3.927
  timestamp: 1635258704
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: d7ef0_00001
  
== Status ==
Memory usage on this node: 71.9/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/495.4 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_4_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_0_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_2_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_3_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_1_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_5_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_2_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_3_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_1_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/6.0 CPU_group_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_4_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_5_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_0_a7be4b0b41b93d405011dc3e24ea2af2)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_d7ef0_00000 | RUNNING  | 10.13.39.107:26230 | 0.0001 |               3000 |      1 |          294.869 | 3150 |  24082   |              27658.6 |              19975.5 |                 30 |
| PPO_EdgeCloudEnv1_d7ef0_00001 | RUNNING  | 10.13.39.107:26184 | 0.001  |               3000 |      2 |          673.144 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_d7ef0_00000:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.409523809523808
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 2
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7899.162126828118
    Social Welfare (Random Allocation)_mean: 5457.097407951896
    Social Welfare (Random Allocation)_min: 3888.1292006071553
    Social Welfare_max: 9206.785565279099
    Social Welfare_mean: 7999.137798974094
    Social Welfare_min: 6714.454867620475
  date: 2021-10-26_15-31-45
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27620.3566958373
  episode_reward_mean: 23997.413396922282
  episode_reward_min: 20143.364602861435
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 16144efa422a4568be282eb3f255c2fc
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.584746137556729
          entropy_coeff: 0.0
          kl: 0.018195911197172728
          policy_loss: 0.004404350303557621
          total_loss: 16873026.68738739
          vf_explained_var: 0.014319381676614285
          vf_loss: 16873026.40135135
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 42.58314814814815
    ram_util_percent: 9.582407407407407
  pid: 26230
  policy_reward_max:
    default: 9206.785565279099
  policy_reward_mean:
    default: 7999.137798974094
  policy_reward_min:
    default: 6714.454867620475
  sampler_perf:
    mean_action_processing_ms: 0.1021999673745067
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 477.37154915255275
    mean_inference_ms: 1.8460134964533776
    mean_raw_obs_processing_ms: 6.875377075715635
  time_since_restore: 673.9807574748993
  time_this_iter_s: 379.1117379665375
  time_total_s: 673.9807574748993
  timers:
    learn_throughput: 152.393
    learn_time_ms: 20670.225
    sample_throughput: 9.959
    sample_time_ms: 316300.473
    update_time_ms: 3.479
  timestamp: 1635258705
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: d7ef0_00000
  
Result for PPO_EdgeCloudEnv1_d7ef0_00001:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.533333333333335
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 6.20952380952381
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7561.037728969207
    Social Welfare (Random Allocation)_mean: 5639.056399037374
    Social Welfare (Random Allocation)_min: 3444.0735201120983
    Social Welfare_max: 9393.3159210423
    Social Welfare_mean: 8191.429139103084
    Social Welfare_min: 6668.9270033924095
  date: 2021-10-26_15-39-59
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28179.947763126926
  episode_reward_mean: 24574.287417309253
  episode_reward_min: 20006.78101017722
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: d8122bd7ec9d4c6493a4fb13e97960ae
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.4500000000000001
          cur_lr: 0.001
          entropy: 0.9873753228405804
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15913675058977092
          total_loss: .inf
          vf_explained_var: 0.16473977267742157
          vf_loss: 16097216.598648649
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 42.21600566572238
    ram_util_percent: 9.309348441926344
  pid: 26184
  policy_reward_max:
    default: 9393.3159210423
  policy_reward_mean:
    default: 8191.429139103086
  policy_reward_min:
    default: 6668.9270033924095
  sampler_perf:
    mean_action_processing_ms: 0.1002028529319985
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 561.2920059595456
    mean_inference_ms: 1.8528898199798567
    mean_raw_obs_processing_ms: 7.798660929905301
  time_since_restore: 1168.075704574585
  time_this_iter_s: 494.9317367076874
  time_total_s: 1168.075704574585
  timers:
    learn_throughput: 149.169
    learn_time_ms: 21117.046
    sample_throughput: 8.555
    sample_time_ms: 368222.095
    update_time_ms: 3.583
  timestamp: 1635259199
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: d7ef0_00001
  
== Status ==
Memory usage on this node: 71.9/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/495.4 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_3_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_4_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_1_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_4_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_5_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_2_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/6.0 CPU_group_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_2_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_5_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_0_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_3_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_1_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/6.0 CPU_group_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_0_a7be4b0b41b93d405011dc3e24ea2af2)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_d7ef0_00000 | RUNNING  | 10.13.39.107:26230 | 0.0001 |               3000 |      2 |          673.981 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_d7ef0_00001 | RUNNING  | 10.13.39.107:26184 | 0.001  |               3000 |      3 |         1168.08  | 9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_d7ef0_00000:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.419047619047618
    Allocated Tasks Number_min: 27
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.828571428571428
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7500.308337068168
    Social Welfare (Random Allocation)_mean: 5593.45734795943
    Social Welfare (Random Allocation)_min: 3758.2663214270156
    Social Welfare_max: 9294.820375261532
    Social Welfare_mean: 8038.417341800684
    Social Welfare_min: 6445.078494603251
  date: 2021-10-26_15-40-00
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27884.4611257846
  episode_reward_mean: 24115.252025402053
  episode_reward_min: 19335.23548380974
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 16144efa422a4568be282eb3f255c2fc
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5625350365767607
          entropy_coeff: 0.0
          kl: 0.023187605126125617
          policy_loss: 0.008069554482049704
          total_loss: 16464452.908108108
          vf_explained_var: 0.03559638187289238
          vf_loss: 16464452.673423423
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 42.21148936170213
    ram_util_percent: 9.309078014184397
  pid: 26230
  policy_reward_max:
    default: 9294.820375261532
  policy_reward_mean:
    default: 8038.417341800683
  policy_reward_min:
    default: 6445.078494603251
  sampler_perf:
    mean_action_processing_ms: 0.10210841121905573
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 549.770041510644
    mean_inference_ms: 1.8706076111130336
    mean_raw_obs_processing_ms: 7.786030897950447
  time_since_restore: 1168.4559741020203
  time_this_iter_s: 494.475216627121
  time_total_s: 1168.4559741020203
  timers:
    learn_throughput: 152.686
    learn_time_ms: 20630.527
    sample_throughput: 8.54
    sample_time_ms: 368833.628
    update_time_ms: 3.614
  timestamp: 1635259200
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: d7ef0_00000
  
Result for PPO_EdgeCloudEnv1_d7ef0_00000:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.64761904761905
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7595.848139463799
    Social Welfare (Random Allocation)_mean: 5713.912731429197
    Social Welfare (Random Allocation)_min: 4210.0886792356905
    Social Welfare_max: 9356.013150952798
    Social Welfare_mean: 8157.091040975737
    Social Welfare_min: 6596.6455070559105
  date: 2021-10-26_15-42-54
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28068.039452858404
  episode_reward_mean: 24471.273122927214
  episode_reward_min: 19789.936521167747
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 16144efa422a4568be282eb3f255c2fc
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.00010000000000000003
          entropy: 1.545704576507345
          entropy_coeff: 0.0
          kl: 0.0212652327241367
          policy_loss: 0.007853564555307868
          total_loss: 16564141.26036036
          vf_explained_var: 0.04438931494951248
          vf_loss: 16564141.00045045
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 43.9574297188755
    ram_util_percent: 9.534538152610443
  pid: 26230
  policy_reward_max:
    default: 9356.013150952798
  policy_reward_mean:
    default: 8157.091040975736
  policy_reward_min:
    default: 6596.6455070559105
  sampler_perf:
    mean_action_processing_ms: 0.10155127758735799
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 469.6478201916463
    mean_inference_ms: 1.8627039452764258
    mean_raw_obs_processing_ms: 6.889924829037404
  time_since_restore: 1343.0475685596466
  time_this_iter_s: 174.59159445762634
  time_total_s: 1343.0475685596466
  timers:
    learn_throughput: 153.744
    learn_time_ms: 20488.625
    sample_throughput: 9.992
    sample_time_ms: 315251.755
    update_time_ms: 3.498
  timestamp: 1635259374
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: d7ef0_00000
  
== Status ==
Memory usage on this node: 71.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/495.4 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_2_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/6.0 CPU_group_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_4_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_2_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/6.0 CPU_group_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_4_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_5_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_1_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_3_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_5_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_0_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_0_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_3_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_1_7b89ee5622bd1b7d3a63111b52e3aefa)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_d7ef0_00000 | RUNNING  | 10.13.39.107:26230 | 0.0001 |               3000 |      4 |          1343.05 | 12600 |  24471.3 |              28068   |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_d7ef0_00001 | RUNNING  | 10.13.39.107:26184 | 0.001  |               3000 |      3 |          1168.08 |  9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_d7ef0_00001:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.79047619047619
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 15
    Bad Allocations Number_mean: 7.104761904761904
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7226.507746909067
    Social Welfare (Random Allocation)_mean: 5645.498463884971
    Social Welfare (Random Allocation)_min: 4284.401252245399
    Social Welfare_max: 9260.343498766093
    Social Welfare_mean: 8414.514033610567
    Social Welfare_min: 6964.4019115518095
  date: 2021-10-26_15-42-56
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27781.03049629827
  episode_reward_mean: 25243.5421008317
  episode_reward_min: 20893.205734655414
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: d8122bd7ec9d4c6493a4fb13e97960ae
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.6749999999999998
          cur_lr: 0.001
          entropy: 0.9576918035449724
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.16871869819425467
          total_loss: .inf
          vf_explained_var: 0.1990945041179657
          vf_loss: 16136426.923873873
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 43.95617529880478
    ram_util_percent: 9.533864541832669
  pid: 26184
  policy_reward_max:
    default: 9260.343498766093
  policy_reward_mean:
    default: 8414.514033610567
  policy_reward_min:
    default: 6964.4019115518095
  sampler_perf:
    mean_action_processing_ms: 0.09969108306146339
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 479.63867531745797
    mean_inference_ms: 1.8414240136878537
    mean_raw_obs_processing_ms: 6.834298360447047
  time_since_restore: 1344.6038308143616
  time_this_iter_s: 176.5281262397766
  time_total_s: 1344.6038308143616
  timers:
    learn_throughput: 147.904
    learn_time_ms: 21297.645
    sample_throughput: 10.005
    sample_time_ms: 314834.117
    update_time_ms: 3.454
  timestamp: 1635259376
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: d7ef0_00001
  
== Status ==
Memory usage on this node: 70.3/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/495.4 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/6.0 CPU_group_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_0_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_0_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_1_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_3_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_2_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_4_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_5_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_1_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_2_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_5_7b89ee5622bd1b7d3a63111b52e3aefa, 0.0/1.0 CPU_group_3_a7be4b0b41b93d405011dc3e24ea2af2, 0.0/1.0 CPU_group_4_a7be4b0b41b93d405011dc3e24ea2af2)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 TERMINATED)
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc   |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_d7ef0_00000 | TERMINATED |       | 0.0001 |               3000 |      4 |          1343.05 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_d7ef0_00001 | TERMINATED |       | 0.001  |               3000 |      4 |          1344.6  | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x2b71fc8372b0>
2021-10-26 15:43:29,552	INFO services.py:1247 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
[2m[36m(pid=37788)[0m 2021-10-26 15:43:59,380	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=37765)[0m 2021-10-26 15:43:59,380	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=37751)[0m 2021-10-26 15:44:06,291	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37762)[0m 2021-10-26 15:44:06,283	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37795)[0m 2021-10-26 15:44:06,288	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37794)[0m 2021-10-26 15:44:06,283	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37781)[0m 2021-10-26 15:44:06,283	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37779)[0m 2021-10-26 15:44:06,283	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37748)[0m 2021-10-26 15:44:06,283	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37763)[0m 2021-10-26 15:44:06,288	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37743)[0m 2021-10-26 15:44:06,283	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37768)[0m 2021-10-26 15:44:06,283	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37788)[0m 2021-10-26 15:44:06,500	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37765)[0m 2021-10-26 15:44:06,502	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=37788)[0m 2021-10-26 15:44:06,576	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=37765)[0m 2021-10-26 15:44:06,582	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=37763)[0m 2021-10-26 15:44:06,630	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
[2m[36m(pid=37743)[0m 2021-10-26 15:44:06,637	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
2021-10-26 15:47:04,167	INFO tune.py:545 -- Total run time: 206.06 seconds (204.84 seconds for the tuning loop).
The seed = 124
The random seed = 537

<class 'environments.edge_cloud.simulation.environment.EdgeCloudEnv1'>
start training
== Status ==
Memory usage on this node: 71.0/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/496.78 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 PENDING)
+-------------------------------+----------+-------+--------+--------------------+
| Trial name                    | status   | loc   |     lr |   train_batch_size |
|-------------------------------+----------+-------+--------+--------------------|
| PPO_EdgeCloudEnv1_1ad39_00000 | PENDING  |       | 0.0001 |               3000 |
| PPO_EdgeCloudEnv1_1ad39_00001 | PENDING  |       | 0.001  |               3000 |
+-------------------------------+----------+-------+--------+--------------------+


Result for PPO_EdgeCloudEnv1_1ad39_00000:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-44-46
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 9dc0dbf118944cd2af561fdf7898c2c8
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5996981921496691
          entropy_coeff: 0.0
          kl: 0.008815318613239533
          policy_loss: 0.0014780368991531767
          total_loss: 17552714.26891892
          vf_explained_var: 0.0035156048834323883
          vf_loss: 17552713.961711712
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.931578947368422
    ram_util_percent: 8.914035087719297
  pid: 37765
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.09914955888799556
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.086684340342476
    mean_inference_ms: 1.6781526586710933
    mean_raw_obs_processing_ms: 1.6196579638449402
  time_since_restore: 39.7936749458313
  time_this_iter_s: 39.7936749458313
  time_total_s: 39.7936749458313
  timers:
    learn_throughput: 174.826
    learn_time_ms: 18017.914
    sample_throughput: 144.823
    sample_time_ms: 21750.699
    update_time_ms: 4.188
  timestamp: 1635259486
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: 1ad39_00000
  
== Status ==
Memory usage on this node: 67.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/496.78 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_1ad39_00000 | RUNNING  | 10.13.39.107:37765 | 0.0001 |               3000 |      1 |          39.7937 | 3150 |    24082 |              27658.6 |              19975.5 |                 30 |
| PPO_EdgeCloudEnv1_1ad39_00001 | RUNNING  |                    | 0.001  |               3000 |        |                  |      |          |                      |                      |                    |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_1ad39_00001:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-44-50
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 292a6a0a35204139a8ec2092262a7872
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.001
          entropy: 1.513871910443177
          entropy_coeff: 0.0
          kl: 0.11704072306168711
          policy_loss: 0.05776758837566852
          total_loss: 17551071.286486488
          vf_explained_var: 0.019300125539302826
          vf_loss: 17551070.964864865
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.80634920634921
    ram_util_percent: 8.915873015873014
  pid: 37788
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.0982813525313243
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.060210054158784
    mean_inference_ms: 1.6252810905928088
    mean_raw_obs_processing_ms: 1.6165786991028699
  time_since_restore: 44.09220743179321
  time_this_iter_s: 44.09220743179321
  time_total_s: 44.09220743179321
  timers:
    learn_throughput: 144.354
    learn_time_ms: 21821.292
    sample_throughput: 141.584
    sample_time_ms: 22248.341
    update_time_ms: 4.184
  timestamp: 1635259490
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: 1ad39_00001
  
Result for PPO_EdgeCloudEnv1_1ad39_00000:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.409523809523808
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 2
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7899.162126828118
    Social Welfare (Random Allocation)_mean: 5457.097407951896
    Social Welfare (Random Allocation)_min: 3888.1292006071553
    Social Welfare_max: 9206.785565279099
    Social Welfare_mean: 7999.137798974094
    Social Welfare_min: 6714.454867620475
  date: 2021-10-26_15-45-26
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27620.3566958373
  episode_reward_mean: 23997.413396922282
  episode_reward_min: 20143.364602861435
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 9dc0dbf118944cd2af561fdf7898c2c8
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.584746137556729
          entropy_coeff: 0.0
          kl: 0.018195911197172728
          policy_loss: 0.004404350303557621
          total_loss: 16873026.68738739
          vf_explained_var: 0.014319381676614285
          vf_loss: 16873026.40135135
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.47586206896552
    ram_util_percent: 8.944827586206896
  pid: 37765
  policy_reward_max:
    default: 9206.785565279099
  policy_reward_mean:
    default: 7999.137798974094
  policy_reward_min:
    default: 6714.454867620475
  sampler_perf:
    mean_action_processing_ms: 0.09683757240482965
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.781978759947126
    mean_inference_ms: 1.6657968440952047
    mean_raw_obs_processing_ms: 1.6816948067092592
  time_since_restore: 80.04929327964783
  time_this_iter_s: 40.25561833381653
  time_total_s: 80.04929327964783
  timers:
    learn_throughput: 170.348
    learn_time_ms: 18491.561
    sample_throughput: 146.442
    sample_time_ms: 21510.227
    update_time_ms: 3.735
  timestamp: 1635259526
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: 1ad39_00000
  
== Status ==
Memory usage on this node: 67.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/496.78 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_2_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_0_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_5_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_0_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_3_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_5_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_2_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_4_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/6.0 CPU_group_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_3_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_1_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_1_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_4_e3591d58ffc77f40788173429bff4167)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_1ad39_00000 | RUNNING  | 10.13.39.107:37765 | 0.0001 |               3000 |      2 |          80.0493 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_1ad39_00001 | RUNNING  | 10.13.39.107:37788 | 0.001  |               3000 |      1 |          44.0922 | 3150 |  24082   |              27658.6 |              19975.5 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_1ad39_00001:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 28.60952380952381
    Allocated Tasks Number_min: 25
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.504761904761905
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7886.312692320824
    Social Welfare (Random Allocation)_mean: 5454.690507335335
    Social Welfare (Random Allocation)_min: 3993.6764038328247
    Social Welfare_max: 8857.690324940027
    Social Welfare_mean: 7595.790692926532
    Social Welfare_min: 6212.450802427609
  date: 2021-10-26_15-45-34
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 26573.070974820075
  episode_reward_mean: 22787.372078779597
  episode_reward_min: 18637.3524072828
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 292a6a0a35204139a8ec2092262a7872
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.001
          entropy: 1.2516942950142074
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15826879244482328
          total_loss: .inf
          vf_explained_var: 0.08230109512805939
          vf_loss: 14567135.024324324
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.51269841269841
    ram_util_percent: 8.949206349206348
  pid: 37788
  policy_reward_max:
    default: 8857.690324940027
  policy_reward_mean:
    default: 7595.790692926533
  policy_reward_min:
    default: 6212.450802427609
  sampler_perf:
    mean_action_processing_ms: 0.09625137655816318
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.91237065604903
    mean_inference_ms: 1.6107823147270814
    mean_raw_obs_processing_ms: 1.6294454790882231
  time_since_restore: 87.80241394042969
  time_this_iter_s: 43.710206508636475
  time_total_s: 87.80241394042969
  timers:
    learn_throughput: 144.574
    learn_time_ms: 21788.205
    sample_throughput: 142.598
    sample_time_ms: 22090.08
    update_time_ms: 3.824
  timestamp: 1635259534
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: 1ad39_00001
  
== Status ==
Memory usage on this node: 67.7/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/496.78 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_0_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_2_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_3_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/6.0 CPU_group_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_1_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_2_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_5_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_3_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_4_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/6.0 CPU_group_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_1_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_0_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_5_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_4_e3591d58ffc77f40788173429bff4167)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_1ad39_00000 | RUNNING  | 10.13.39.107:37765 | 0.0001 |               3000 |      2 |          80.0493 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_1ad39_00001 | RUNNING  | 10.13.39.107:37788 | 0.001  |               3000 |      2 |          87.8024 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_1ad39_00000:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.419047619047618
    Allocated Tasks Number_min: 27
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.828571428571428
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7500.308337068168
    Social Welfare (Random Allocation)_mean: 5593.45734795943
    Social Welfare (Random Allocation)_min: 3758.2663214270156
    Social Welfare_max: 9294.820375261532
    Social Welfare_mean: 8038.417341800684
    Social Welfare_min: 6445.078494603251
  date: 2021-10-26_15-46-07
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27884.4611257846
  episode_reward_mean: 24115.252025402053
  episode_reward_min: 19335.23548380974
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 9dc0dbf118944cd2af561fdf7898c2c8
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5625350365767607
          entropy_coeff: 0.0
          kl: 0.023187605126125617
          policy_loss: 0.008069554482049704
          total_loss: 16464452.908108108
          vf_explained_var: 0.03559638187289238
          vf_loss: 16464452.673423423
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.368965517241378
    ram_util_percent: 8.958620689655174
  pid: 37765
  policy_reward_max:
    default: 9294.820375261532
  policy_reward_mean:
    default: 8038.417341800683
  policy_reward_min:
    default: 6445.078494603251
  sampler_perf:
    mean_action_processing_ms: 0.0959313653374021
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.69150379307998
    mean_inference_ms: 1.657594819979211
    mean_raw_obs_processing_ms: 1.6546823308935623
  time_since_restore: 120.42289423942566
  time_this_iter_s: 40.37360095977783
  time_total_s: 120.42289423942566
  timers:
    learn_throughput: 168.246
    learn_time_ms: 18722.593
    sample_throughput: 147.218
    sample_time_ms: 21396.857
    update_time_ms: 3.614
  timestamp: 1635259567
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: 1ad39_00000
  
== Status ==
Memory usage on this node: 67.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/496.78 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_0_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_2_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_3_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/6.0 CPU_group_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_1_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_2_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_5_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_3_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_4_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/6.0 CPU_group_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_1_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_0_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_5_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_4_e3591d58ffc77f40788173429bff4167)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_1ad39_00000 | RUNNING  | 10.13.39.107:37765 | 0.0001 |               3000 |      3 |         120.423  | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_1ad39_00001 | RUNNING  | 10.13.39.107:37788 | 0.001  |               3000 |      2 |          87.8024 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_1ad39_00001:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.533333333333335
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 6.20952380952381
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7561.037728969207
    Social Welfare (Random Allocation)_mean: 5639.056399037374
    Social Welfare (Random Allocation)_min: 3444.0735201120983
    Social Welfare_max: 9393.3159210423
    Social Welfare_mean: 8191.429139103084
    Social Welfare_min: 6668.9270033924095
  date: 2021-10-26_15-46-19
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28179.947763126926
  episode_reward_mean: 24574.287417309253
  episode_reward_min: 20006.78101017722
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 292a6a0a35204139a8ec2092262a7872
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.4500000000000001
          cur_lr: 0.001
          entropy: 0.9873753228405804
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15913675058977092
          total_loss: .inf
          vf_explained_var: 0.16473977267742157
          vf_loss: 16097216.598648649
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.421875
    ram_util_percent: 8.9578125
  pid: 37788
  policy_reward_max:
    default: 9393.3159210423
  policy_reward_mean:
    default: 8191.429139103086
  policy_reward_min:
    default: 6668.9270033924095
  sampler_perf:
    mean_action_processing_ms: 0.09545203178159652
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.79058084634168
    mean_inference_ms: 1.6103034924729553
    mean_raw_obs_processing_ms: 1.6223658587427001
  time_since_restore: 132.5784170627594
  time_this_iter_s: 44.77600312232971
  time_total_s: 132.5784170627594
  timers:
    learn_throughput: 141.779
    learn_time_ms: 22217.678
    sample_throughput: 143.506
    sample_time_ms: 21950.295
    update_time_ms: 3.744
  timestamp: 1635259579
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: 1ad39_00001
  
== Status ==
Memory usage on this node: 67.7/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/496.78 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_3_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/6.0 CPU_group_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_0_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_2_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_5_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_1_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/6.0 CPU_group_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_1_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_5_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_3_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_2_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_4_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_4_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_0_e3591d58ffc77f40788173429bff4167)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_1ad39_00000 | RUNNING  | 10.13.39.107:37765 | 0.0001 |               3000 |      3 |          120.423 | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_1ad39_00001 | RUNNING  | 10.13.39.107:37788 | 0.001  |               3000 |      3 |          132.578 | 9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_1ad39_00000:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.64761904761905
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7595.848139463799
    Social Welfare (Random Allocation)_mean: 5713.912731429197
    Social Welfare (Random Allocation)_min: 4210.0886792356905
    Social Welfare_max: 9356.013150952798
    Social Welfare_mean: 8157.091040975737
    Social Welfare_min: 6596.6455070559105
  date: 2021-10-26_15-46-47
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28068.039452858404
  episode_reward_mean: 24471.273122927214
  episode_reward_min: 19789.936521167747
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 9dc0dbf118944cd2af561fdf7898c2c8
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.00010000000000000003
          entropy: 1.545704576507345
          entropy_coeff: 0.0
          kl: 0.0212652327241367
          policy_loss: 0.007853564555307868
          total_loss: 16564141.26036036
          vf_explained_var: 0.04438931494951248
          vf_loss: 16564141.00045045
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.79642857142857
    ram_util_percent: 8.975
  pid: 37765
  policy_reward_max:
    default: 9356.013150952798
  policy_reward_mean:
    default: 8157.091040975736
  policy_reward_min:
    default: 6596.6455070559105
  sampler_perf:
    mean_action_processing_ms: 0.09519396581048295
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.500606617063156
    mean_inference_ms: 1.6425662549513287
    mean_raw_obs_processing_ms: 1.6341827919160692
  time_since_restore: 160.16684484481812
  time_this_iter_s: 39.743950605392456
  time_total_s: 160.16684484481812
  timers:
    learn_throughput: 167.068
    learn_time_ms: 18854.6
    sample_throughput: 148.821
    sample_time_ms: 21166.342
    update_time_ms: 3.228
  timestamp: 1635259607
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: 1ad39_00000
  
== Status ==
Memory usage on this node: 67.7/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/496.78 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_4_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_1_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_3_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_5_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/6.0 CPU_group_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_2_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_0_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_1_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_4_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_3_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_5_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_2_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_0_e3591d58ffc77f40788173429bff4167)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_1ad39_00000 | RUNNING  | 10.13.39.107:37765 | 0.0001 |               3000 |      4 |          160.167 | 12600 |  24471.3 |              28068   |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_1ad39_00001 | RUNNING  | 10.13.39.107:37788 | 0.001  |               3000 |      3 |          132.578 |  9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_1ad39_00001:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.79047619047619
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 15
    Bad Allocations Number_mean: 7.104761904761904
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7226.507746909067
    Social Welfare (Random Allocation)_mean: 5645.498463884971
    Social Welfare (Random Allocation)_min: 4284.401252245399
    Social Welfare_max: 9260.343498766093
    Social Welfare_mean: 8414.514033610567
    Social Welfare_min: 6964.4019115518095
  date: 2021-10-26_15-47-03
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27781.03049629827
  episode_reward_mean: 25243.5421008317
  episode_reward_min: 20893.205734655414
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 292a6a0a35204139a8ec2092262a7872
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.6749999999999998
          cur_lr: 0.001
          entropy: 0.9576918035449724
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.16871869819425467
          total_loss: .inf
          vf_explained_var: 0.1990945041179657
          vf_loss: 16136426.923873873
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.006349206349206
    ram_util_percent: 8.846031746031748
  pid: 37788
  policy_reward_max:
    default: 9260.343498766093
  policy_reward_mean:
    default: 8414.514033610567
  policy_reward_min:
    default: 6964.4019115518095
  sampler_perf:
    mean_action_processing_ms: 0.09509735001500096
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 29.59456725614216
    mean_inference_ms: 1.5991675480165821
    mean_raw_obs_processing_ms: 1.6120057028468198
  time_since_restore: 176.87429285049438
  time_this_iter_s: 44.295875787734985
  time_total_s: 176.87429285049438
  timers:
    learn_throughput: 140.029
    learn_time_ms: 22495.387
    sample_throughput: 145.168
    sample_time_ms: 21698.983
    update_time_ms: 3.667
  timestamp: 1635259623
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: 1ad39_00001
  
== Status ==
Memory usage on this node: 64.7/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 6.0/64 CPUs, 0/0 GPUs, 0.0/496.78 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_0_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_0_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_5_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_2_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_3_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_1_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_2_e3591d58ffc77f40788173429bff4167, 0.0/6.0 CPU_group_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_3_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_5_e3591d58ffc77f40788173429bff4167, 0.0/6.0 CPU_group_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_4_e3591d58ffc77f40788173429bff4167, 0.0/1.0 CPU_group_4_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_1_e3591d58ffc77f40788173429bff4167)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_1ad39_00001 | RUNNING    | 10.13.39.107:37788 | 0.001  |               3000 |      4 |          176.874 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
| PPO_EdgeCloudEnv1_1ad39_00000 | TERMINATED |                    | 0.0001 |               3000 |      4 |          160.167 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 64.7/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/496.78 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_3_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_1_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/6.0 CPU_group_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_2_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_5_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_0_f8cf0f3ff03fe5a37b4e065d9ca59ed6, 0.0/1.0 CPU_group_4_f8cf0f3ff03fe5a37b4e065d9ca59ed6)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 TERMINATED)
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc   |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_1ad39_00000 | TERMINATED |       | 0.0001 |               3000 |      4 |          160.167 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_1ad39_00001 | TERMINATED |       | 0.001  |               3000 |      4 |          176.874 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x2b277bf032e8>
2021-10-26 15:47:22,093	INFO services.py:1247 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
[2m[36m(pid=42011)[0m 2021-10-26 15:47:39,380	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=41992)[0m 2021-10-26 15:47:39,380	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=41975)[0m 2021-10-26 15:47:44,826	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=42001)[0m 2021-10-26 15:47:44,825	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=41995)[0m 2021-10-26 15:47:44,826	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=42009)[0m 2021-10-26 15:47:44,826	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=41970)[0m 2021-10-26 15:47:44,827	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=42005)[0m 2021-10-26 15:47:44,825	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=41980)[0m 2021-10-26 15:47:44,825	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=42000)[0m 2021-10-26 15:47:44,825	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=41979)[0m 2021-10-26 15:47:44,825	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=41974)[0m 2021-10-26 15:47:44,825	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=42011)[0m 2021-10-26 15:47:44,955	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=41992)[0m 2021-10-26 15:47:44,955	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=42011)[0m 2021-10-26 15:47:45,031	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=41992)[0m 2021-10-26 15:47:45,031	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=42001)[0m 2021-10-26 15:47:45,120	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
[2m[36m(pid=41995)[0m 2021-10-26 15:47:45,087	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
2021-10-26 15:50:41,225	INFO tune.py:545 -- Total run time: 190.96 seconds (190.40 seconds for the tuning loop).
The seed = 124
The random seed = 199

<class 'environments.edge_cloud.simulation.environment.EdgeCloudEnv1'>
start training
== Status ==
Memory usage on this node: 76.8/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/502.95 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 PENDING)
+-------------------------------+----------+-------+--------+--------------------+
| Trial name                    | status   | loc   |     lr |   train_batch_size |
|-------------------------------+----------+-------+--------+--------------------|
| PPO_EdgeCloudEnv1_a5338_00000 | PENDING  |       | 0.0001 |               3000 |
| PPO_EdgeCloudEnv1_a5338_00001 | PENDING  |       | 0.001  |               3000 |
+-------------------------------+----------+-------+--------+--------------------+


Result for PPO_EdgeCloudEnv1_a5338_00001:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-48-27
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 8aedfdc609ad42e5afd2d16771e0226d
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.001
          entropy: 1.513871910443177
          entropy_coeff: 0.0
          kl: 0.11704072306168711
          policy_loss: 0.05776758837566852
          total_loss: 17551071.286486488
          vf_explained_var: 0.019300125539302826
          vf_loss: 17551070.964864865
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.27213114754098
    ram_util_percent: 11.160655737704923
  pid: 42011
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10426063356233287
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.304623330262878
    mean_inference_ms: 1.747123488533516
    mean_raw_obs_processing_ms: 1.777009389668751
  time_since_restore: 42.21856355667114
  time_this_iter_s: 42.21856355667114
  time_total_s: 42.21856355667114
  timers:
    learn_throughput: 154.273
    learn_time_ms: 20418.316
    sample_throughput: 144.65
    sample_time_ms: 21776.708
    update_time_ms: 3.835
  timestamp: 1635259707
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: a5338_00001
  
== Status ==
Memory usage on this node: 88.2/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/502.95 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_a5338_00000 | RUNNING  |                    | 0.0001 |               3000 |        |                  |      |          |                      |                      |                    |
| PPO_EdgeCloudEnv1_a5338_00001 | RUNNING  | 10.13.39.107:42011 | 0.001  |               3000 |      1 |          42.2186 | 3150 |    24082 |              27658.6 |              19975.5 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_a5338_00000:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-48-28
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: f1ea051175cb445fab24436a319e2d4e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5996981921496691
          entropy_coeff: 0.0
          kl: 0.008815318613239533
          policy_loss: 0.0014780368991531767
          total_loss: 17552714.26891892
          vf_explained_var: 0.0035156048834323883
          vf_loss: 17552713.961711712
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.25967741935483
    ram_util_percent: 11.169354838709683
  pid: 41992
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10986630398951316
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 31.34248819668585
    mean_inference_ms: 1.8696259016469237
    mean_raw_obs_processing_ms: 1.7002891625164047
  time_since_restore: 43.349958419799805
  time_this_iter_s: 43.349958419799805
  time_total_s: 43.349958419799805
  timers:
    learn_throughput: 161.196
    learn_time_ms: 19541.457
    sample_throughput: 132.416
    sample_time_ms: 23788.676
    update_time_ms: 3.605
  timestamp: 1635259708
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: a5338_00000
  
Result for PPO_EdgeCloudEnv1_a5338_00001:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 28.60952380952381
    Allocated Tasks Number_min: 25
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.504761904761905
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7886.312692320824
    Social Welfare (Random Allocation)_mean: 5454.690507335335
    Social Welfare (Random Allocation)_min: 3993.6764038328247
    Social Welfare_max: 8857.690324940027
    Social Welfare_mean: 7595.790692926532
    Social Welfare_min: 6212.450802427609
  date: 2021-10-26_15-49-10
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 26573.070974820075
  episode_reward_mean: 22787.372078779597
  episode_reward_min: 18637.3524072828
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 8aedfdc609ad42e5afd2d16771e0226d
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.001
          entropy: 1.2516942950142074
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15826879244482328
          total_loss: .inf
          vf_explained_var: 0.08230109512805939
          vf_loss: 14567135.024324324
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.3032258064516
    ram_util_percent: 12.908064516129029
  pid: 42011
  policy_reward_max:
    default: 8857.690324940027
  policy_reward_mean:
    default: 7595.790692926533
  policy_reward_min:
    default: 6212.450802427609
  sampler_perf:
    mean_action_processing_ms: 0.10063842967046241
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.097558288513714
    mean_inference_ms: 1.711616357293609
    mean_raw_obs_processing_ms: 1.722163987670221
  time_since_restore: 85.81839346885681
  time_this_iter_s: 43.59982991218567
  time_total_s: 85.81839346885681
  timers:
    learn_throughput: 147.668
    learn_time_ms: 21331.631
    sample_throughput: 146.134
    sample_time_ms: 21555.49
    update_time_ms: 3.453
  timestamp: 1635259750
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: a5338_00001
  
== Status ==
Memory usage on this node: 105.5/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/502.95 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_3_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_5_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_4_d417b323e81a631ff22b9a74fe663545, 0.0/6.0 CPU_group_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_2_d417b323e81a631ff22b9a74fe663545, 0.0/6.0 CPU_group_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_5_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_0_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_0_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_1_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_2_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_4_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_3_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_1_d417b323e81a631ff22b9a74fe663545)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_a5338_00000 | RUNNING  | 10.13.39.107:41992 | 0.0001 |               3000 |      1 |          43.35   | 3150 |  24082   |              27658.6 |              19975.5 |                 30 |
| PPO_EdgeCloudEnv1_a5338_00001 | RUNNING  | 10.13.39.107:42011 | 0.001  |               3000 |      2 |          85.8184 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_a5338_00000:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.409523809523808
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 2
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7899.162126828118
    Social Welfare (Random Allocation)_mean: 5457.097407951896
    Social Welfare (Random Allocation)_min: 3888.1292006071553
    Social Welfare_max: 9206.785565279099
    Social Welfare_mean: 7999.137798974094
    Social Welfare_min: 6714.454867620475
  date: 2021-10-26_15-49-11
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27620.3566958373
  episode_reward_mean: 23997.413396922282
  episode_reward_min: 20143.364602861435
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: f1ea051175cb445fab24436a319e2d4e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.584746137556729
          entropy_coeff: 0.0
          kl: 0.018195911197172728
          policy_loss: 0.004404350303557621
          total_loss: 16873026.68738739
          vf_explained_var: 0.014319381676614285
          vf_loss: 16873026.40135135
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.26612903225806
    ram_util_percent: 12.945161290322577
  pid: 41992
  policy_reward_max:
    default: 9206.785565279099
  policy_reward_mean:
    default: 7999.137798974094
  policy_reward_min:
    default: 6714.454867620475
  sampler_perf:
    mean_action_processing_ms: 0.1038463979746783
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.69997211943346
    mean_inference_ms: 1.7966184230383948
    mean_raw_obs_processing_ms: 1.735837869848362
  time_since_restore: 86.33840489387512
  time_this_iter_s: 42.98844647407532
  time_total_s: 86.33840489387512
  timers:
    learn_throughput: 155.359
    learn_time_ms: 20275.61
    sample_throughput: 137.733
    sample_time_ms: 22870.36
    update_time_ms: 3.38
  timestamp: 1635259751
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: a5338_00000
  
Result for PPO_EdgeCloudEnv1_a5338_00001:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.533333333333335
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 6.20952380952381
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7561.037728969207
    Social Welfare (Random Allocation)_mean: 5639.056399037374
    Social Welfare (Random Allocation)_min: 3444.0735201120983
    Social Welfare_max: 9393.3159210423
    Social Welfare_mean: 8191.429139103084
    Social Welfare_min: 6668.9270033924095
  date: 2021-10-26_15-49-55
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28179.947763126926
  episode_reward_mean: 24574.287417309253
  episode_reward_min: 20006.78101017722
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 8aedfdc609ad42e5afd2d16771e0226d
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.4500000000000001
          cur_lr: 0.001
          entropy: 0.9873753228405804
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15913675058977092
          total_loss: .inf
          vf_explained_var: 0.16473977267742157
          vf_loss: 16097216.598648649
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.699999999999996
    ram_util_percent: 14.547619047619046
  pid: 42011
  policy_reward_max:
    default: 9393.3159210423
  policy_reward_mean:
    default: 8191.429139103086
  policy_reward_min:
    default: 6668.9270033924095
  sampler_perf:
    mean_action_processing_ms: 0.10054627150722689
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.20972489428105
    mean_inference_ms: 1.7219358622744123
    mean_raw_obs_processing_ms: 1.700579962485811
  time_since_restore: 130.26858592033386
  time_this_iter_s: 44.45019245147705
  time_total_s: 130.26858592033386
  timers:
    learn_throughput: 144.619
    learn_time_ms: 21781.362
    sample_throughput: 145.699
    sample_time_ms: 21619.876
    update_time_ms: 3.409
  timestamp: 1635259795
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: a5338_00001
  
== Status ==
Memory usage on this node: 119.0/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/502.95 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_1_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_5_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_2_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_1_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_0_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_5_8a348b6f986f0cd03463524725b8f274, 0.0/6.0 CPU_group_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_2_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_4_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_3_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_0_8a348b6f986f0cd03463524725b8f274, 0.0/6.0 CPU_group_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_4_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_3_8a348b6f986f0cd03463524725b8f274)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_a5338_00000 | RUNNING  | 10.13.39.107:41992 | 0.0001 |               3000 |      2 |          86.3384 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_a5338_00001 | RUNNING  | 10.13.39.107:42011 | 0.001  |               3000 |      3 |         130.269  | 9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_a5338_00000:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.419047619047618
    Allocated Tasks Number_min: 27
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.828571428571428
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7500.308337068168
    Social Welfare (Random Allocation)_mean: 5593.45734795943
    Social Welfare (Random Allocation)_min: 3758.2663214270156
    Social Welfare_max: 9294.820375261532
    Social Welfare_mean: 8038.417341800684
    Social Welfare_min: 6445.078494603251
  date: 2021-10-26_15-49-56
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27884.4611257846
  episode_reward_mean: 24115.252025402053
  episode_reward_min: 19335.23548380974
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: f1ea051175cb445fab24436a319e2d4e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5625350365767607
          entropy_coeff: 0.0
          kl: 0.023187605126125617
          policy_loss: 0.008069554482049704
          total_loss: 16464452.908108108
          vf_explained_var: 0.03559638187289238
          vf_loss: 16464452.673423423
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.66461538461538
    ram_util_percent: 14.612307692307692
  pid: 41992
  policy_reward_max:
    default: 9294.820375261532
  policy_reward_mean:
    default: 8038.417341800683
  policy_reward_min:
    default: 6445.078494603251
  sampler_perf:
    mean_action_processing_ms: 0.10264561581019052
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.6020839828338
    mean_inference_ms: 1.7834616236936354
    mean_raw_obs_processing_ms: 1.7555776693907947
  time_since_restore: 131.82335591316223
  time_this_iter_s: 45.48495101928711
  time_total_s: 131.82335591316223
  timers:
    learn_throughput: 148.47
    learn_time_ms: 21216.361
    sample_throughput: 138.758
    sample_time_ms: 22701.329
    update_time_ms: 3.442
  timestamp: 1635259796
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: a5338_00000
  
Result for PPO_EdgeCloudEnv1_a5338_00001:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.79047619047619
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 15
    Bad Allocations Number_mean: 7.104761904761904
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7226.507746909067
    Social Welfare (Random Allocation)_mean: 5645.498463884971
    Social Welfare (Random Allocation)_min: 4284.401252245399
    Social Welfare_max: 9260.343498766093
    Social Welfare_mean: 8414.514033610567
    Social Welfare_min: 6964.4019115518095
  date: 2021-10-26_15-50-40
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27781.03049629827
  episode_reward_mean: 25243.5421008317
  episode_reward_min: 20893.205734655414
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 8aedfdc609ad42e5afd2d16771e0226d
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.6749999999999998
          cur_lr: 0.001
          entropy: 0.9576918035449724
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.16871869819425467
          total_loss: .inf
          vf_explained_var: 0.1990945041179657
          vf_loss: 16136426.923873873
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.58125
    ram_util_percent: 15.704687499999999
  pid: 42011
  policy_reward_max:
    default: 9260.343498766093
  policy_reward_mean:
    default: 8414.514033610567
  policy_reward_min:
    default: 6964.4019115518095
  sampler_perf:
    mean_action_processing_ms: 0.10081133829228041
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.239906012184417
    mean_inference_ms: 1.732082416121329
    mean_raw_obs_processing_ms: 1.6911182456525342
  time_since_restore: 175.08764147758484
  time_this_iter_s: 44.81905555725098
  time_total_s: 175.08764147758484
  timers:
    learn_throughput: 142.904
    learn_time_ms: 22042.748
    sample_throughput: 145.109
    sample_time_ms: 21707.768
    update_time_ms: 3.119
  timestamp: 1635259840
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: a5338_00001
  
== Status ==
Memory usage on this node: 118.5/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/502.95 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_4_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_3_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_4_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_0_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_5_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_0_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_2_8a348b6f986f0cd03463524725b8f274, 0.0/6.0 CPU_group_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_3_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_2_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_5_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_1_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_1_d417b323e81a631ff22b9a74fe663545, 0.0/6.0 CPU_group_8a348b6f986f0cd03463524725b8f274)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_a5338_00000 | RUNNING  | 10.13.39.107:41992 | 0.0001 |               3000 |      3 |          131.823 |  9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_a5338_00001 | RUNNING  | 10.13.39.107:42011 | 0.001  |               3000 |      4 |          175.088 | 12600 |  25243.5 |              27781   |              20893.2 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_a5338_00000:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.64761904761905
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7595.848139463799
    Social Welfare (Random Allocation)_mean: 5713.912731429197
    Social Welfare (Random Allocation)_min: 4210.0886792356905
    Social Welfare_max: 9356.013150952798
    Social Welfare_mean: 8157.091040975737
    Social Welfare_min: 6596.6455070559105
  date: 2021-10-26_15-50-40
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28068.039452858404
  episode_reward_mean: 24471.273122927214
  episode_reward_min: 19789.936521167747
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: f1ea051175cb445fab24436a319e2d4e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.00010000000000000003
          entropy: 1.545704576507345
          entropy_coeff: 0.0
          kl: 0.0212652327241367
          policy_loss: 0.007853564555307868
          total_loss: 16564141.26036036
          vf_explained_var: 0.04438931494951248
          vf_loss: 16564141.00045045
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.59032258064516
    ram_util_percent: 15.700000000000001
  pid: 41992
  policy_reward_max:
    default: 9356.013150952798
  policy_reward_mean:
    default: 8157.091040975736
  policy_reward_min:
    default: 6596.6455070559105
  sampler_perf:
    mean_action_processing_ms: 0.10221274019186104
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.493614608359113
    mean_inference_ms: 1.782680153610308
    mean_raw_obs_processing_ms: 1.7373915940511326
  time_since_restore: 175.61172318458557
  time_this_iter_s: 43.78836727142334
  time_total_s: 175.61172318458557
  timers:
    learn_throughput: 147.027
    learn_time_ms: 21424.599
    sample_throughput: 140.283
    sample_time_ms: 22454.591
    update_time_ms: 3.843
  timestamp: 1635259840
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: a5338_00000
  
== Status ==
Memory usage on this node: 118.4/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/502.95 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_4_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_0_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_5_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_4_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_3_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_2_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_1_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_0_d417b323e81a631ff22b9a74fe663545, 0.0/1.0 CPU_group_3_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_1_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_2_8a348b6f986f0cd03463524725b8f274, 0.0/1.0 CPU_group_5_8a348b6f986f0cd03463524725b8f274, 0.0/6.0 CPU_group_d417b323e81a631ff22b9a74fe663545, 0.0/6.0 CPU_group_8a348b6f986f0cd03463524725b8f274)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 TERMINATED)
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc   |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_a5338_00000 | TERMINATED |       | 0.0001 |               3000 |      4 |          175.612 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_a5338_00001 | TERMINATED |       | 0.001  |               3000 |      4 |          175.088 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x2b219ddaa358>
2021-10-26 15:51:03,619	INFO services.py:1247 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
[2m[36m(pid=44998)[0m 2021-10-26 15:51:20,511	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=45013)[0m 2021-10-26 15:51:20,511	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=45035)[0m 2021-10-26 15:51:26,395	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=45009)[0m 2021-10-26 15:51:26,397	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=45026)[0m 2021-10-26 15:51:26,398	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=45029)[0m 2021-10-26 15:51:26,396	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=44985)[0m 2021-10-26 15:51:26,397	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=44978)[0m 2021-10-26 15:51:26,396	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=44993)[0m 2021-10-26 15:51:26,396	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=45033)[0m 2021-10-26 15:51:26,395	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=44991)[0m 2021-10-26 15:51:26,398	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=44988)[0m 2021-10-26 15:51:26,396	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=44998)[0m 2021-10-26 15:51:26,502	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=45013)[0m 2021-10-26 15:51:26,502	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=44998)[0m 2021-10-26 15:51:26,578	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=45013)[0m 2021-10-26 15:51:26,578	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=45035)[0m 2021-10-26 15:51:26,644	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
[2m[36m(pid=45009)[0m 2021-10-26 15:51:26,644	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
2021-10-26 15:54:27,072	INFO tune.py:545 -- Total run time: 194.50 seconds (193.81 seconds for the tuning loop).
The seed = 124
The random seed = 899

<class 'environments.edge_cloud.simulation.environment.EdgeCloudEnv1'>
start training
== Status ==
Memory usage on this node: 117.2/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/450.32 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 PENDING)
+-------------------------------+----------+-------+--------+--------------------+
| Trial name                    | status   | loc   |     lr |   train_batch_size |
|-------------------------------+----------+-------+--------+--------------------|
| PPO_EdgeCloudEnv1_29b52_00000 | PENDING  |       | 0.0001 |               3000 |
| PPO_EdgeCloudEnv1_29b52_00001 | PENDING  |       | 0.001  |               3000 |
+-------------------------------+----------+-------+--------+--------------------+


Result for PPO_EdgeCloudEnv1_29b52_00000:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-52-09
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 2736d1e117274ae3bf9a71689780cd2d
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5996981921496691
          entropy_coeff: 0.0
          kl: 0.008815318613239533
          policy_loss: 0.0014780368991531767
          total_loss: 17552714.26891892
          vf_explained_var: 0.0035156048834323883
          vf_loss: 17552713.961711712
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.64354838709678
    ram_util_percent: 15.841935483870966
  pid: 44998
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10550396189258894
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 31.597026743337207
    mean_inference_ms: 1.8156186903335403
    mean_raw_obs_processing_ms: 1.86024936367706
  time_since_restore: 43.09851002693176
  time_this_iter_s: 43.09851002693176
  time_total_s: 43.09851002693176
  timers:
    learn_throughput: 156.418
    learn_time_ms: 20138.309
    sample_throughput: 137.307
    sample_time_ms: 22941.313
    update_time_ms: 3.48
  timestamp: 1635259929
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: 29b52_00000
  
== Status ==
Memory usage on this node: 120.1/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/450.32 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_29b52_00000 | RUNNING  | 10.13.39.107:44998 | 0.0001 |               3000 |      1 |          43.0985 | 3150 |    24082 |              27658.6 |              19975.5 |                 30 |
| PPO_EdgeCloudEnv1_29b52_00001 | RUNNING  |                    | 0.001  |               3000 |        |                  |      |          |                      |                      |                    |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_29b52_00001:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-52-11
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: da5801a1ca3141dfa6dcd207fdb4085e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.001
          entropy: 1.513871910443177
          entropy_coeff: 0.0
          kl: 0.11704072306168711
          policy_loss: 0.05776758837566852
          total_loss: 17551071.286486488
          vf_explained_var: 0.019300125539302826
          vf_loss: 17551070.964864865
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.915384615384625
    ram_util_percent: 15.844615384615386
  pid: 45013
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10562147089116357
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 31.47799738235594
    mean_inference_ms: 1.8122147833677553
    mean_raw_obs_processing_ms: 1.6906529712223592
  time_since_restore: 45.16624474525452
  time_this_iter_s: 45.16624474525452
  time_total_s: 45.16624474525452
  timers:
    learn_throughput: 142.075
    learn_time_ms: 22171.462
    sample_throughput: 137.162
    sample_time_ms: 22965.627
    update_time_ms: 3.314
  timestamp: 1635259931
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: 29b52_00001
  
Result for PPO_EdgeCloudEnv1_29b52_00000:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.409523809523808
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 2
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7899.162126828118
    Social Welfare (Random Allocation)_mean: 5457.097407951896
    Social Welfare (Random Allocation)_min: 3888.1292006071553
    Social Welfare_max: 9206.785565279099
    Social Welfare_mean: 7999.137798974094
    Social Welfare_min: 6714.454867620475
  date: 2021-10-26_15-52-52
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27620.3566958373
  episode_reward_mean: 23997.413396922282
  episode_reward_min: 20143.364602861435
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 2736d1e117274ae3bf9a71689780cd2d
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.584746137556729
          entropy_coeff: 0.0
          kl: 0.018195911197172728
          policy_loss: 0.004404350303557621
          total_loss: 16873026.68738739
          vf_explained_var: 0.014319381676614285
          vf_loss: 16873026.40135135
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.467213114754095
    ram_util_percent: 15.870491803278686
  pid: 44998
  policy_reward_max:
    default: 9206.785565279099
  policy_reward_mean:
    default: 7999.137798974094
  policy_reward_min:
    default: 6714.454867620475
  sampler_perf:
    mean_action_processing_ms: 0.10470512081572786
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 31.06442734327324
    mean_inference_ms: 1.7852251913507815
    mean_raw_obs_processing_ms: 1.7620510189047323
  time_since_restore: 86.03012132644653
  time_this_iter_s: 42.93161129951477
  time_total_s: 86.03012132644653
  timers:
    learn_throughput: 153.456
    learn_time_ms: 20527.085
    sample_throughput: 140.199
    sample_time_ms: 22467.993
    update_time_ms: 3.251
  timestamp: 1635259972
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: 29b52_00000
  
== Status ==
Memory usage on this node: 119.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/450.32 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_1_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_1_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_5_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_3_120ae951704d0465371b94182164705a, 0.0/6.0 CPU_group_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_3_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_0_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_5_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_4_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_0_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_2_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_4_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_2_120ae951704d0465371b94182164705a)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_29b52_00000 | RUNNING  | 10.13.39.107:44998 | 0.0001 |               3000 |      2 |          86.0301 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_29b52_00001 | RUNNING  | 10.13.39.107:45013 | 0.001  |               3000 |      1 |          45.1662 | 3150 |  24082   |              27658.6 |              19975.5 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_29b52_00001:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 28.60952380952381
    Allocated Tasks Number_min: 25
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.504761904761905
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7886.312692320824
    Social Welfare (Random Allocation)_mean: 5454.690507335335
    Social Welfare (Random Allocation)_min: 3993.6764038328247
    Social Welfare_max: 8857.690324940027
    Social Welfare_mean: 7595.790692926532
    Social Welfare_min: 6212.450802427609
  date: 2021-10-26_15-52-56
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 26573.070974820075
  episode_reward_mean: 22787.372078779597
  episode_reward_min: 18637.3524072828
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: da5801a1ca3141dfa6dcd207fdb4085e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.001
          entropy: 1.2516942950142074
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15826879244482328
          total_loss: .inf
          vf_explained_var: 0.08230109512805939
          vf_loss: 14567135.024324324
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.0609375
    ram_util_percent: 15.868749999999999
  pid: 45013
  policy_reward_max:
    default: 8857.690324940027
  policy_reward_mean:
    default: 7595.790692926533
  policy_reward_min:
    default: 6212.450802427609
  sampler_perf:
    mean_action_processing_ms: 0.10264492715567847
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.94836362858408
    mean_inference_ms: 1.792905445991292
    mean_raw_obs_processing_ms: 1.6674020193948524
  time_since_restore: 89.78552770614624
  time_this_iter_s: 44.619282960891724
  time_total_s: 89.78552770614624
  timers:
    learn_throughput: 140.526
    learn_time_ms: 22415.833
    sample_throughput: 140.322
    sample_time_ms: 22448.445
    update_time_ms: 3.349
  timestamp: 1635259976
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: 29b52_00001
  
Result for PPO_EdgeCloudEnv1_29b52_00000:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.419047619047618
    Allocated Tasks Number_min: 27
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.828571428571428
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7500.308337068168
    Social Welfare (Random Allocation)_mean: 5593.45734795943
    Social Welfare (Random Allocation)_min: 3758.2663214270156
    Social Welfare_max: 9294.820375261532
    Social Welfare_mean: 8038.417341800684
    Social Welfare_min: 6445.078494603251
  date: 2021-10-26_15-53-35
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27884.4611257846
  episode_reward_mean: 24115.252025402053
  episode_reward_min: 19335.23548380974
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 2736d1e117274ae3bf9a71689780cd2d
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5625350365767607
          entropy_coeff: 0.0
          kl: 0.023187605126125617
          policy_loss: 0.008069554482049704
          total_loss: 16464452.908108108
          vf_explained_var: 0.03559638187289238
          vf_loss: 16464452.673423423
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.88387096774194
    ram_util_percent: 15.872580645161287
  pid: 44998
  policy_reward_max:
    default: 9294.820375261532
  policy_reward_mean:
    default: 8038.417341800683
  policy_reward_min:
    default: 6445.078494603251
  sampler_perf:
    mean_action_processing_ms: 0.10286060859764899
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.966173915368806
    mean_inference_ms: 1.7697910982613079
    mean_raw_obs_processing_ms: 1.7251310999087082
  time_since_restore: 128.96879363059998
  time_this_iter_s: 42.93867230415344
  time_total_s: 128.96879363059998
  timers:
    learn_throughput: 152.217
    learn_time_ms: 20694.173
    sample_throughput: 141.417
    sample_time_ms: 22274.565
    update_time_ms: 3.319
  timestamp: 1635260015
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: 29b52_00000
  
== Status ==
Memory usage on this node: 119.8/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/450.32 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_0_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_1_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_0_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_1_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_3_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_3_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_4_1d9c7790184ccab48159d2538ddd529d, 0.0/6.0 CPU_group_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_5_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_2_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_5_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_2_120ae951704d0465371b94182164705a, 0.0/6.0 CPU_group_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_4_120ae951704d0465371b94182164705a)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_29b52_00000 | RUNNING  | 10.13.39.107:44998 | 0.0001 |               3000 |      3 |         128.969  | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_29b52_00001 | RUNNING  | 10.13.39.107:45013 | 0.001  |               3000 |      2 |          89.7855 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_29b52_00001:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.533333333333335
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 6.20952380952381
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7561.037728969207
    Social Welfare (Random Allocation)_mean: 5639.056399037374
    Social Welfare (Random Allocation)_min: 3444.0735201120983
    Social Welfare_max: 9393.3159210423
    Social Welfare_mean: 8191.429139103084
    Social Welfare_min: 6668.9270033924095
  date: 2021-10-26_15-53-41
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28179.947763126926
  episode_reward_mean: 24574.287417309253
  episode_reward_min: 20006.78101017722
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: da5801a1ca3141dfa6dcd207fdb4085e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.4500000000000001
          cur_lr: 0.001
          entropy: 0.9873753228405804
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15913675058977092
          total_loss: .inf
          vf_explained_var: 0.16473977267742157
          vf_loss: 16097216.598648649
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.965625
    ram_util_percent: 15.865625000000001
  pid: 45013
  policy_reward_max:
    default: 9393.3159210423
  policy_reward_mean:
    default: 8191.429139103086
  policy_reward_min:
    default: 6668.9270033924095
  sampler_perf:
    mean_action_processing_ms: 0.10206940185450042
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.99279673499194
    mean_inference_ms: 1.7913692783010755
    mean_raw_obs_processing_ms: 1.659778562694047
  time_since_restore: 134.9135444164276
  time_this_iter_s: 45.12801671028137
  time_total_s: 134.9135444164276
  timers:
    learn_throughput: 139.63
    learn_time_ms: 22559.633
    sample_throughput: 140.719
    sample_time_ms: 22384.988
    update_time_ms: 3.226
  timestamp: 1635260021
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: 29b52_00001
  
== Status ==
Memory usage on this node: 119.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/450.32 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_0_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_2_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_5_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_0_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_3_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_1_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_4_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_3_120ae951704d0465371b94182164705a, 0.0/6.0 CPU_group_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_5_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_4_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_1_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_2_1d9c7790184ccab48159d2538ddd529d, 0.0/6.0 CPU_group_120ae951704d0465371b94182164705a)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_29b52_00000 | RUNNING  | 10.13.39.107:44998 | 0.0001 |               3000 |      3 |          128.969 | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_29b52_00001 | RUNNING  | 10.13.39.107:45013 | 0.001  |               3000 |      3 |          134.914 | 9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_29b52_00000:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.64761904761905
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7595.848139463799
    Social Welfare (Random Allocation)_mean: 5713.912731429197
    Social Welfare (Random Allocation)_min: 4210.0886792356905
    Social Welfare_max: 9356.013150952798
    Social Welfare_mean: 8157.091040975737
    Social Welfare_min: 6596.6455070559105
  date: 2021-10-26_15-54-18
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28068.039452858404
  episode_reward_mean: 24471.273122927214
  episode_reward_min: 19789.936521167747
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 2736d1e117274ae3bf9a71689780cd2d
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.00010000000000000003
          entropy: 1.545704576507345
          entropy_coeff: 0.0
          kl: 0.0212652327241367
          policy_loss: 0.007853564555307868
          total_loss: 16564141.26036036
          vf_explained_var: 0.04438931494951248
          vf_loss: 16564141.00045045
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.324999999999996
    ram_util_percent: 15.848333333333333
  pid: 44998
  policy_reward_max:
    default: 9356.013150952798
  policy_reward_mean:
    default: 8157.091040975736
  policy_reward_min:
    default: 6596.6455070559105
  sampler_perf:
    mean_action_processing_ms: 0.1017483866720718
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.735712891200002
    mean_inference_ms: 1.7636623329607468
    mean_raw_obs_processing_ms: 1.701296099307564
  time_since_restore: 171.4869360923767
  time_this_iter_s: 42.51814246177673
  time_total_s: 171.4869360923767
  timers:
    learn_throughput: 151.569
    learn_time_ms: 20782.577
    sample_throughput: 142.74
    sample_time_ms: 22068.085
    update_time_ms: 3.303
  timestamp: 1635260058
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: 29b52_00000
  
== Status ==
Memory usage on this node: 120.1/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/450.32 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_0_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_2_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_5_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_0_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_3_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_1_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_4_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_3_120ae951704d0465371b94182164705a, 0.0/6.0 CPU_group_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_5_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_4_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_1_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_2_1d9c7790184ccab48159d2538ddd529d, 0.0/6.0 CPU_group_120ae951704d0465371b94182164705a)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_29b52_00000 | RUNNING  | 10.13.39.107:44998 | 0.0001 |               3000 |      4 |          171.487 | 12600 |  24471.3 |              28068   |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_29b52_00001 | RUNNING  | 10.13.39.107:45013 | 0.001  |               3000 |      3 |          134.914 |  9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_29b52_00001:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.79047619047619
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 15
    Bad Allocations Number_mean: 7.104761904761904
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7226.507746909067
    Social Welfare (Random Allocation)_mean: 5645.498463884971
    Social Welfare (Random Allocation)_min: 4284.401252245399
    Social Welfare_max: 9260.343498766093
    Social Welfare_mean: 8414.514033610567
    Social Welfare_min: 6964.4019115518095
  date: 2021-10-26_15-54-26
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27781.03049629827
  episode_reward_mean: 25243.5421008317
  episode_reward_min: 20893.205734655414
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: da5801a1ca3141dfa6dcd207fdb4085e
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.6749999999999998
          cur_lr: 0.001
          entropy: 0.9576918035449724
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.16871869819425467
          total_loss: .inf
          vf_explained_var: 0.1990945041179657
          vf_loss: 16136426.923873873
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.599999999999994
    ram_util_percent: 15.84375
  pid: 45013
  policy_reward_max:
    default: 9260.343498766093
  policy_reward_mean:
    default: 8414.514033610567
  policy_reward_min:
    default: 6964.4019115518095
  sampler_perf:
    mean_action_processing_ms: 0.1013825971519413
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.756526729125245
    mean_inference_ms: 1.7842695288410364
    mean_raw_obs_processing_ms: 1.6610695227229937
  time_since_restore: 179.72474765777588
  time_this_iter_s: 44.81120324134827
  time_total_s: 179.72474765777588
  timers:
    learn_throughput: 139.05
    learn_time_ms: 22653.657
    sample_throughput: 141.557
    sample_time_ms: 22252.506
    update_time_ms: 3.24
  timestamp: 1635260066
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: 29b52_00001
  
== Status ==
Memory usage on this node: 119.3/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 6.0/64 CPUs, 0/0 GPUs, 0.0/450.32 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_1_120ae951704d0465371b94182164705a, 0.0/6.0 CPU_group_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_0_120ae951704d0465371b94182164705a, 0.0/6.0 CPU_group_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_2_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_3_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_4_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_5_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_3_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_4_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_1_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_5_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_2_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_0_1d9c7790184ccab48159d2538ddd529d)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_29b52_00001 | RUNNING    | 10.13.39.107:45013 | 0.001  |               3000 |      4 |          179.725 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
| PPO_EdgeCloudEnv1_29b52_00000 | TERMINATED |                    | 0.0001 |               3000 |      4 |          171.487 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 119.0/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/450.32 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_1_120ae951704d0465371b94182164705a, 0.0/6.0 CPU_group_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_0_120ae951704d0465371b94182164705a, 0.0/6.0 CPU_group_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_2_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_3_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_4_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_5_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_3_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_4_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_1_1d9c7790184ccab48159d2538ddd529d, 0.0/1.0 CPU_group_5_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_2_120ae951704d0465371b94182164705a, 0.0/1.0 CPU_group_0_1d9c7790184ccab48159d2538ddd529d)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 TERMINATED)
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc   |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_29b52_00000 | TERMINATED |       | 0.0001 |               3000 |      4 |          171.487 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_29b52_00001 | TERMINATED |       | 0.001  |               3000 |      4 |          179.725 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x2b1aa60513c8>
2021-10-26 15:54:59,309	INFO services.py:1247 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
[2m[36m(pid=49451)[0m 2021-10-26 15:55:27,904	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=49410)[0m 2021-10-26 15:55:27,904	INFO trainer.py:716 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=49433)[0m 2021-10-26 15:55:35,826	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49405)[0m 2021-10-26 15:55:35,832	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49445)[0m 2021-10-26 15:55:35,837	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49429)[0m 2021-10-26 15:55:35,829	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49442)[0m 2021-10-26 15:55:35,830	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49449)[0m 2021-10-26 15:55:35,826	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49431)[0m 2021-10-26 15:55:35,826	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49450)[0m 2021-10-26 15:55:35,826	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49421)[0m 2021-10-26 15:55:35,826	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49452)[0m 2021-10-26 15:55:35,826	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49451)[0m 2021-10-26 15:55:36,018	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49451)[0m 2021-10-26 15:55:36,094	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=49410)[0m 2021-10-26 15:55:36,018	WARNING catalog.py:549 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(pid=49410)[0m 2021-10-26 15:55:36,094	WARNING util.py:55 -- Install gputil for GPU system monitoring.
[2m[36m(pid=49433)[0m 2021-10-26 15:55:36,153	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
[2m[36m(pid=49405)[0m 2021-10-26 15:55:36,156	WARNING deprecation.py:34 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, **kwargs)` instead. This will raise an error in the future!
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
2021-10-26 15:58:35,102	INFO tune.py:545 -- Total run time: 207.46 seconds (205.99 seconds for the tuning loop).
The seed = 124
The random seed = 380

<class 'environments.edge_cloud.simulation.environment.EdgeCloudEnv1'>
start training
== Status ==
Memory usage on this node: 119.0/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/449.08 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 PENDING)
+-------------------------------+----------+-------+--------+--------------------+
| Trial name                    | status   | loc   |     lr |   train_batch_size |
|-------------------------------+----------+-------+--------+--------------------|
| PPO_EdgeCloudEnv1_b5d2b_00000 | PENDING  |       | 0.0001 |               3000 |
| PPO_EdgeCloudEnv1_b5d2b_00001 | PENDING  |       | 0.001  |               3000 |
+-------------------------------+----------+-------+--------+--------------------+


Result for PPO_EdgeCloudEnv1_b5d2b_00000:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-56-19
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: e6c586a3fb20441e88810a9205f27de7
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5996981921496691
          entropy_coeff: 0.0
          kl: 0.008815318613239533
          policy_loss: 0.0014780368991531767
          total_loss: 17552714.26891892
          vf_explained_var: 0.0035156048834323883
          vf_loss: 17552713.961711712
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.83064516129033
    ram_util_percent: 16.080645161290327
  pid: 49410
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10600588778875143
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 31.430776976934517
    mean_inference_ms: 1.8210460191294433
    mean_raw_obs_processing_ms: 1.689037468089544
  time_since_restore: 42.95081043243408
  time_this_iter_s: 42.95081043243408
  time_total_s: 42.95081043243408
  timers:
    learn_throughput: 156.556
    learn_time_ms: 20120.637
    sample_throughput: 138.109
    sample_time_ms: 22808.02
    update_time_ms: 3.76
  timestamp: 1635260179
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: b5d2b_00000
  
== Status ==
Memory usage on this node: 121.3/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/449.08 GiB heap, 0.0/186.26 GiB objects
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_b5d2b_00000 | RUNNING  | 10.13.39.107:49410 | 0.0001 |               3000 |      1 |          42.9508 | 3150 |    24082 |              27658.6 |              19975.5 |                 30 |
| PPO_EdgeCloudEnv1_b5d2b_00001 | RUNNING  |                    | 0.001  |               3000 |        |                  |      |          |                      |                      |                    |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_b5d2b_00001:
  agent_timesteps_total: 9450
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.16190476190476
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.533333333333333
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 9093.853088651103
    Social Welfare (Online Myopic)_min: 8192.785553567319
    Social Welfare (Random Allocation)_max: 7303.550598850631
    Social Welfare (Random Allocation)_mean: 5534.4087877916845
    Social Welfare (Random Allocation)_min: 3456.818754324206
    Social Welfare_max: 9219.519948703215
    Social Welfare_mean: 8027.326145670626
    Social Welfare_min: 6658.489940328781
  date: 2021-10-26_15-56-19
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27658.559846109656
  episode_reward_mean: 24081.978437011876
  episode_reward_min: 19975.46982098633
  episodes_this_iter: 105
  episodes_total: 105
  experiment_id: 70da0c6bc8fb4572aea7ef6d82ae92b5
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.001
          entropy: 1.513871910443177
          entropy_coeff: 0.0
          kl: 0.11704072306168711
          policy_loss: 0.05776758837566852
          total_loss: 17551071.286486488
          vf_explained_var: 0.019300125539302826
          vf_loss: 17551070.964864865
        model: {}
    num_agent_steps_sampled: 9450
    num_agent_steps_trained: 9450
    num_steps_sampled: 3150
    num_steps_trained: 3150
  iterations_since_restore: 1
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.78571428571429
    ram_util_percent: 16.082539682539686
  pid: 49451
  policy_reward_max:
    default: 9219.519948703215
  policy_reward_mean:
    default: 8027.326145670627
  policy_reward_min:
    default: 6658.489940328781
  sampler_perf:
    mean_action_processing_ms: 0.10384825632424816
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 31.18427400543648
    mean_inference_ms: 1.8372791882740152
    mean_raw_obs_processing_ms: 1.6722648910788465
  time_since_restore: 43.65409588813782
  time_this_iter_s: 43.65409588813782
  time_total_s: 43.65409588813782
  timers:
    learn_throughput: 149.925
    learn_time_ms: 21010.445
    sample_throughput: 139.232
    sample_time_ms: 22624.172
    update_time_ms: 3.214
  timestamp: 1635260179
  timesteps_since_restore: 0
  timesteps_total: 3150
  training_iteration: 1
  trial_id: b5d2b_00001
  
Result for PPO_EdgeCloudEnv1_b5d2b_00000:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.409523809523808
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 2
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7899.162126828118
    Social Welfare (Random Allocation)_mean: 5457.097407951896
    Social Welfare (Random Allocation)_min: 3888.1292006071553
    Social Welfare_max: 9206.785565279099
    Social Welfare_mean: 7999.137798974094
    Social Welfare_min: 6714.454867620475
  date: 2021-10-26_15-57-02
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27620.3566958373
  episode_reward_mean: 23997.413396922282
  episode_reward_min: 20143.364602861435
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: e6c586a3fb20441e88810a9205f27de7
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.584746137556729
          entropy_coeff: 0.0
          kl: 0.018195911197172728
          policy_loss: 0.004404350303557621
          total_loss: 16873026.68738739
          vf_explained_var: 0.014319381676614285
          vf_loss: 16873026.40135135
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.38196721311476
    ram_util_percent: 16.08360655737705
  pid: 49410
  policy_reward_max:
    default: 9206.785565279099
  policy_reward_mean:
    default: 7999.137798974094
  policy_reward_min:
    default: 6714.454867620475
  sampler_perf:
    mean_action_processing_ms: 0.1033074320733405
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 31.00836997368711
    mean_inference_ms: 1.8085615867475588
    mean_raw_obs_processing_ms: 1.6772428644166686
  time_since_restore: 85.98891878128052
  time_this_iter_s: 43.038108348846436
  time_total_s: 85.98891878128052
  timers:
    learn_throughput: 153.785
    learn_time_ms: 20483.082
    sample_throughput: 140.059
    sample_time_ms: 22490.54
    update_time_ms: 3.414
  timestamp: 1635260222
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: b5d2b_00000
  
== Status ==
Memory usage on this node: 121.2/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/449.08 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_1_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/6.0 CPU_group_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_2_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_0_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_5_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_0_1076d3ee0c7612f711ffc578b862ff1e, 0.0/6.0 CPU_group_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_4_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_5_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_4_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_3_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_2_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_3_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_1_1076d3ee0c7612f711ffc578b862ff1e)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_b5d2b_00000 | RUNNING  | 10.13.39.107:49410 | 0.0001 |               3000 |      2 |          85.9889 | 6300 |  23997.4 |              27620.4 |              20143.4 |                 30 |
| PPO_EdgeCloudEnv1_b5d2b_00001 | RUNNING  | 10.13.39.107:49451 | 0.001  |               3000 |      1 |          43.6541 | 3150 |  24082   |              27658.6 |              19975.5 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_b5d2b_00001:
  agent_timesteps_total: 18900
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 28.60952380952381
    Allocated Tasks Number_min: 25
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.504761904761905
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9887.298120835676
    Social Welfare (Online Myopic)_mean: 8807.242033750053
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7886.312692320824
    Social Welfare (Random Allocation)_mean: 5454.690507335335
    Social Welfare (Random Allocation)_min: 3993.6764038328247
    Social Welfare_max: 8857.690324940027
    Social Welfare_mean: 7595.790692926532
    Social Welfare_min: 6212.450802427609
  date: 2021-10-26_15-57-03
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 26573.070974820075
  episode_reward_mean: 22787.372078779597
  episode_reward_min: 18637.3524072828
  episodes_this_iter: 105
  episodes_total: 210
  experiment_id: 70da0c6bc8fb4572aea7ef6d82ae92b5
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.001
          entropy: 1.2516942950142074
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15826879244482328
          total_loss: .inf
          vf_explained_var: 0.08230109512805939
          vf_loss: 14567135.024324324
        model: {}
    num_agent_steps_sampled: 18900
    num_agent_steps_trained: 18900
    num_steps_sampled: 6300
    num_steps_trained: 6300
  iterations_since_restore: 2
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.35714285714286
    ram_util_percent: 16.082539682539682
  pid: 49451
  policy_reward_max:
    default: 8857.690324940027
  policy_reward_mean:
    default: 7595.790692926533
  policy_reward_min:
    default: 6212.450802427609
  sampler_perf:
    mean_action_processing_ms: 0.10118503404174123
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.66618909540864
    mean_inference_ms: 1.8040360201927148
    mean_raw_obs_processing_ms: 1.6571636714224396
  time_since_restore: 87.67436790466309
  time_this_iter_s: 44.02027201652527
  time_total_s: 87.67436790466309
  timers:
    learn_throughput: 145.362
    learn_time_ms: 21670.027
    sample_throughput: 142.233
    sample_time_ms: 22146.683
    update_time_ms: 3.326
  timestamp: 1635260223
  timesteps_since_restore: 0
  timesteps_total: 6300
  training_iteration: 2
  trial_id: b5d2b_00001
  
Result for PPO_EdgeCloudEnv1_b5d2b_00000:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.419047619047618
    Allocated Tasks Number_min: 27
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 5.828571428571428
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7500.308337068168
    Social Welfare (Random Allocation)_mean: 5593.45734795943
    Social Welfare (Random Allocation)_min: 3758.2663214270156
    Social Welfare_max: 9294.820375261532
    Social Welfare_mean: 8038.417341800684
    Social Welfare_min: 6445.078494603251
  date: 2021-10-26_15-57-45
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27884.4611257846
  episode_reward_mean: 24115.252025402053
  episode_reward_min: 19335.23548380974
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: e6c586a3fb20441e88810a9205f27de7
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.19999999999999996
          cur_lr: 0.00010000000000000003
          entropy: 1.5625350365767607
          entropy_coeff: 0.0
          kl: 0.023187605126125617
          policy_loss: 0.008069554482049704
          total_loss: 16464452.908108108
          vf_explained_var: 0.03559638187289238
          vf_loss: 16464452.673423423
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.20952380952382
    ram_util_percent: 16.082539682539686
  pid: 49410
  policy_reward_max:
    default: 9294.820375261532
  policy_reward_mean:
    default: 8038.417341800683
  policy_reward_min:
    default: 6445.078494603251
  sampler_perf:
    mean_action_processing_ms: 0.1022138398895183
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.85136703559799
    mean_inference_ms: 1.8015384169749515
    mean_raw_obs_processing_ms: 1.6815276072808258
  time_since_restore: 129.7166464328766
  time_this_iter_s: 43.72772765159607
  time_total_s: 129.7166464328766
  timers:
    learn_throughput: 152.412
    learn_time_ms: 20667.639
    sample_throughput: 139.69
    sample_time_ms: 22549.93
    update_time_ms: 3.522
  timestamp: 1635260265
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: b5d2b_00000
  
== Status ==
Memory usage on this node: 121.4/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/449.08 GiB heap, 0.0/186.26 GiB objects (0.0/6.0 CPU_group_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_5_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_2_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_4_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_2_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_3_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_0_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_3_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_1_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_5_1076d3ee0c7612f711ffc578b862ff1e, 0.0/6.0 CPU_group_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_0_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_1_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_4_1076d3ee0c7612f711ffc578b862ff1e)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_b5d2b_00000 | RUNNING  | 10.13.39.107:49410 | 0.0001 |               3000 |      3 |         129.717  | 9450 |  24115.3 |              27884.5 |              19335.2 |                 30 |
| PPO_EdgeCloudEnv1_b5d2b_00001 | RUNNING  | 10.13.39.107:49451 | 0.001  |               3000 |      2 |          87.6744 | 6300 |  22787.4 |              26573.1 |              18637.4 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_b5d2b_00001:
  agent_timesteps_total: 28350
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.533333333333335
    Allocated Tasks Number_min: 26
    Bad Allocations Number_max: 16
    Bad Allocations Number_mean: 6.20952380952381
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9718.733748204579
    Social Welfare (Online Myopic)_mean: 8970.866038916472
    Social Welfare (Online Myopic)_min: 7795.893183921842
    Social Welfare (Random Allocation)_max: 7561.037728969207
    Social Welfare (Random Allocation)_mean: 5639.056399037374
    Social Welfare (Random Allocation)_min: 3444.0735201120983
    Social Welfare_max: 9393.3159210423
    Social Welfare_mean: 8191.429139103084
    Social Welfare_min: 6668.9270033924095
  date: 2021-10-26_15-57-49
  done: false
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28179.947763126926
  episode_reward_mean: 24574.287417309253
  episode_reward_min: 20006.78101017722
  episodes_this_iter: 105
  episodes_total: 315
  experiment_id: 70da0c6bc8fb4572aea7ef6d82ae92b5
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.4500000000000001
          cur_lr: 0.001
          entropy: 0.9873753228405804
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.15913675058977092
          total_loss: .inf
          vf_explained_var: 0.16473977267742157
          vf_loss: 16097216.598648649
        model: {}
    num_agent_steps_sampled: 28350
    num_agent_steps_trained: 28350
    num_steps_sampled: 9450
    num_steps_trained: 9450
  iterations_since_restore: 3
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.26875000000001
    ram_util_percent: 16.084375
  pid: 49451
  policy_reward_max:
    default: 9393.3159210423
  policy_reward_mean:
    default: 8191.429139103086
  policy_reward_min:
    default: 6668.9270033924095
  sampler_perf:
    mean_action_processing_ms: 0.10133281326495673
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.68851322676377
    mean_inference_ms: 1.808205235893294
    mean_raw_obs_processing_ms: 1.6662214370961543
  time_since_restore: 133.10241746902466
  time_this_iter_s: 45.42804956436157
  time_total_s: 133.10241746902466
  timers:
    learn_throughput: 142.39
    learn_time_ms: 22122.331
    sample_throughput: 141.735
    sample_time_ms: 22224.572
    update_time_ms: 3.25
  timestamp: 1635260269
  timesteps_since_restore: 0
  timesteps_total: 9450
  training_iteration: 3
  trial_id: b5d2b_00001
  
Result for PPO_EdgeCloudEnv1_b5d2b_00000:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.64761904761905
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 14
    Bad Allocations Number_mean: 6.152380952380953
    Bad Allocations Number_min: 0
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7595.848139463799
    Social Welfare (Random Allocation)_mean: 5713.912731429197
    Social Welfare (Random Allocation)_min: 4210.0886792356905
    Social Welfare_max: 9356.013150952798
    Social Welfare_mean: 8157.091040975737
    Social Welfare_min: 6596.6455070559105
  date: 2021-10-26_15-58-28
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 28068.039452858404
  episode_reward_mean: 24471.273122927214
  episode_reward_min: 19789.936521167747
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: e6c586a3fb20441e88810a9205f27de7
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.30000000000000004
          cur_lr: 0.00010000000000000003
          entropy: 1.545704576507345
          entropy_coeff: 0.0
          kl: 0.0212652327241367
          policy_loss: 0.007853564555307868
          total_loss: 16564141.26036036
          vf_explained_var: 0.04438931494951248
          vf_loss: 16564141.00045045
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 64.22295081967214
    ram_util_percent: 16.122950819672134
  pid: 49410
  policy_reward_max:
    default: 9356.013150952798
  policy_reward_mean:
    default: 8157.091040975736
  policy_reward_min:
    default: 6596.6455070559105
  sampler_perf:
    mean_action_processing_ms: 0.10205185257315114
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.75695489900824
    mean_inference_ms: 1.7919779675009702
    mean_raw_obs_processing_ms: 1.6747135909858646
  time_since_restore: 172.65082716941833
  time_this_iter_s: 42.93418073654175
  time_total_s: 172.65082716941833
  timers:
    learn_throughput: 151.797
    learn_time_ms: 20751.373
    sample_throughput: 140.692
    sample_time_ms: 22389.285
    update_time_ms: 3.469
  timestamp: 1635260308
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: b5d2b_00000
  
== Status ==
Memory usage on this node: 121.6/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/64 CPUs, 0/0 GPUs, 0.0/449.08 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_3_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_5_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_0_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_2_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_2_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_4_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/6.0 CPU_group_1076d3ee0c7612f711ffc578b862ff1e, 0.0/6.0 CPU_group_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_0_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_3_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_4_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_1_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_5_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_1_1076d3ee0c7612f711ffc578b862ff1e)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 RUNNING)
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status   | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_b5d2b_00000 | RUNNING  | 10.13.39.107:49410 | 0.0001 |               3000 |      4 |          172.651 | 12600 |  24471.3 |              28068   |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_b5d2b_00001 | RUNNING  | 10.13.39.107:49451 | 0.001  |               3000 |      3 |          133.102 |  9450 |  24574.3 |              28179.9 |              20006.8 |                 30 |
+-------------------------------+----------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_EdgeCloudEnv1_b5d2b_00001:
  agent_timesteps_total: 37800
  custom_metrics:
    Allocated Tasks Number_max: 30
    Allocated Tasks Number_mean: 29.79047619047619
    Allocated Tasks Number_min: 28
    Bad Allocations Number_max: 15
    Bad Allocations Number_mean: 7.104761904761904
    Bad Allocations Number_min: 1
    Social Welfare (Online Myopic)_max: 9548.7581621365
    Social Welfare (Online Myopic)_mean: 8998.299992790966
    Social Welfare (Online Myopic)_min: 7940.2185287015
    Social Welfare (Random Allocation)_max: 7226.507746909067
    Social Welfare (Random Allocation)_mean: 5645.498463884971
    Social Welfare (Random Allocation)_min: 4284.401252245399
    Social Welfare_max: 9260.343498766093
    Social Welfare_mean: 8414.514033610567
    Social Welfare_min: 6964.4019115518095
  date: 2021-10-26_15-58-34
  done: true
  episode_len_mean: 30.0
  episode_media: {}
  episode_reward_max: 27781.03049629827
  episode_reward_mean: 25243.5421008317
  episode_reward_min: 20893.205734655414
  episodes_this_iter: 105
  episodes_total: 420
  experiment_id: 70da0c6bc8fb4572aea7ef6d82ae92b5
  hostname: gold52.cluster.local
  info:
    learner:
      default:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_kl_coeff: 0.6749999999999998
          cur_lr: 0.001
          entropy: 0.9576918035449724
          entropy_coeff: 0.0
          kl: .inf
          policy_loss: 0.16871869819425467
          total_loss: .inf
          vf_explained_var: 0.1990945041179657
          vf_loss: 16136426.923873873
        model: {}
    num_agent_steps_sampled: 37800
    num_agent_steps_trained: 37800
    num_steps_sampled: 12600
    num_steps_trained: 12600
  iterations_since_restore: 4
  node_ip: 10.13.39.107
  num_healthy_workers: 5
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.454687500000006
    ram_util_percent: 16.112499999999997
  pid: 49451
  policy_reward_max:
    default: 9260.343498766093
  policy_reward_mean:
    default: 8414.514033610567
  policy_reward_min:
    default: 6964.4019115518095
  sampler_perf:
    mean_action_processing_ms: 0.10083360078078514
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 30.654542836723046
    mean_inference_ms: 1.7988244865868404
    mean_raw_obs_processing_ms: 1.6607778784492009
  time_since_restore: 177.93187928199768
  time_this_iter_s: 44.82946181297302
  time_total_s: 177.93187928199768
  timers:
    learn_throughput: 141.226
    learn_time_ms: 22304.718
    sample_throughput: 142.162
    sample_time_ms: 22157.871
    update_time_ms: 3.245
  timestamp: 1635260314
  timesteps_since_restore: 0
  timesteps_total: 12600
  training_iteration: 4
  trial_id: b5d2b_00001
  
== Status ==
Memory usage on this node: 121.1/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 6.0/64 CPUs, 0/0 GPUs, 0.0/449.08 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_5_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_1_1076d3ee0c7612f711ffc578b862ff1e, 0.0/6.0 CPU_group_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_4_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_3_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/6.0 CPU_group_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_0_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_0_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_1_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_2_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_2_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_5_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_4_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_3_1076d3ee0c7612f711ffc578b862ff1e)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc                |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_b5d2b_00001 | RUNNING    | 10.13.39.107:49451 | 0.001  |               3000 |      4 |          177.932 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
| PPO_EdgeCloudEnv1_b5d2b_00000 | TERMINATED |                    | 0.0001 |               3000 |      4 |          172.651 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
+-------------------------------+------------+--------------------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 121.1/755.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/64 CPUs, 0/0 GPUs, 0.0/449.08 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 CPU_group_5_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_1_1076d3ee0c7612f711ffc578b862ff1e, 0.0/6.0 CPU_group_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_4_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_3_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/6.0 CPU_group_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_0_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_0_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_1_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_2_b84f49e8fe6cd9a3e6ce3895a88b0b94, 0.0/1.0 CPU_group_2_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_5_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_4_1076d3ee0c7612f711ffc578b862ff1e, 0.0/1.0 CPU_group_3_1076d3ee0c7612f711ffc578b862ff1e)
Result logdir: /mainfs/home/fb1n15/MARL-ReverseAuction/marl-edge-cloud/results/edge_cloud_independent_ppo_with_history
Number of trials: 2/2 (2 TERMINATED)
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name                    | status     | loc   |     lr |   train_batch_size |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_EdgeCloudEnv1_b5d2b_00000 | TERMINATED |       | 0.0001 |               3000 |      4 |          172.651 | 12600 |  24471.3 |                28068 |              19789.9 |                 30 |
| PPO_EdgeCloudEnv1_b5d2b_00001 | TERMINATED |       | 0.001  |               3000 |      4 |          177.932 | 12600 |  25243.5 |                27781 |              20893.2 |                 30 |
+-------------------------------+------------+-------+--------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x2ae0ea101e48>
Finishing job
