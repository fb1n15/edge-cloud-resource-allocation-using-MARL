name: gridworld_obstacles_vision_net_ppo

env: gridworld_obstacles_vision_net
env-config:
  width: 40
  height: 40
  num_survivors: 20
  num_agents: 4
  start_world: [ [ ] ]
  sight: 5
  battery: 500
  rewards:
    rescue: 1
    hit tree: 0
    exploring: 0.01
  battery costs:
    rotate left: 1
    rotate right: 1
    advance: 2
  fire spread:
    starting points: 0
    covariance: [ [ 3, 0 ], [ 0, 3 ] ]
    rate: 0.1
  autogen config:
    forest fire:
      chance: 1
      trees:
        scale: 20.0
        octaves: 8
        persistence: 0.5
        lacunarity: 2.0
        threshold: 0.07
      rocks:
        scale: 6.0
        octaves: 10
        persistence: 0.5
        lacunarity: 5.0
        threshold: 0.20
      hq:
        size: 5


trainer: QMIX
trainer-config:
  framework: torch
  num_envs_per_worker: 1
  num_workers: 10
  num_gpus: 1

  # Model config
  model:
    custom_model: "CustomVisionNetwork"
    dim: 11
    conv_filters: [ [ 16, [ 3, 3 ], 2 ], [ 32, [ 3, 3 ], 2 ], [ 512, [ 3, 3 ], 1 ] ]

#    custom_model_config:
#      dim: 11
#      conv_filters: [ [ 16, [ 3, 3 ], 2 ], [ 32, [ 3, 3 ], 2 ], [ 512, [ 3, 3 ], 1 ] ]
    use_lstm: false
    # To further customize the LSTM auto-wrapper
#    "lstm_cell_size": 64

  # Trainer parameters
  lr: 0.00001
  exploration_config:
    # The Exploration class to use.
    "type": EpsilonGreedy
    # Config for the Exploration class' constructor:
    "initial_epsilon": 1.0
    "final_epsilon": 0.02
    "epsilon_timesteps": 25000
#  lambda: 0.9
#  gamma: 0.99
#  rollout_fragment_length: 100
  train_batch_size: 50
#  sgd_minibatch_size: 500
#  entropy_coeff: 0.01


## Use population based trainer
#scheduler: pbt
#scheduler-config:
#  time_attr: training_iteration
#  perturbation_interval: 5
#  metric: episode_reward_mean
#  mode: max
#
#  hyperparam_mutations:
#    lr:
#      loguniform: [0.00001, 0.001]
#    lambda:
#      uniform: [0.9, 1]
#    gamma:
#      uniform: [0.95, 1]
#
#    rollout_fragment_length: [ 20, 100, 200 ]
#    train_batch_size: [ 4000, 5000 ]
#    sgd_minibatch_size: [ 128, 500 ]
#
#    observation_filter: [ MeanStdFilter, NoFilter ]

stop:
  timesteps_total: 2_000_000


grouping: all_same

samples: 1
